spu_data <- spu_metadata %>%
mutate(Spectra=map(spu_filename_full, function(x) read_spu_file_spectra(x)))
spu_dataframe_new <- spu_data %>% select(spu_filename, Site, FileNum, Date, DateTime, Integration_ms, Temp, Remarks, Spectra, everything())
# > Set Type of Scan -----------------------------------------------------
spu_dataframe_new <- spu_dataframe_new %>%
mutate(Type = ifelse(grepl("DARKscan",Remarks, fixed=T), "Darkscan",
ifelse(grepl("Datascan,DC",Remarks, fixed=T), "Throwawayscan", NA))) %>%
distinct(DateTime, spu_filename, .keep_all = T) %>%
mutate(Date = as.character(Date))
# > Join to previously collected data -----------------------------------------------------
spu_dataframe <-  spu_dataframe %>% bind_rows(spu_dataframe_new)
## Standardize Site Names
unique(spu_dataframe$Site)
spu_dataframe$Site <- recode (spu_dataframe$Site, !!!Site_Names, .default = spu_dataframe$Site)
unique(spu_dataframe$Site)
## Data summary
spu_dataframe %>%   group_by(Date, Site) %>%
summarize(Files = n_distinct(spu_filename)) %>%
kable()
field_key <- paste0(data_path, "2019_unispec_field_key.csv")
unispec_field_key <- read_csv(field_key, skip_empty_rows = T, col_types = cols(
Date = col_character(),
Site = col_character(),
Block = col_character(),
Treatment = col_character(),
Replicate = col_double(),
Location = col_character(),
FileNum = col_double(),
Weather = col_character(),
Notes = col_character()
)) ## remove NA rows
# Confirm spu_dataframe has same Site abbreviation as key
# > Standardize Site Names -----------------------------------------------------
# Check for different spelling of site names
unique(spu_dataframe$Site) %>% sort()
# spu_dataframe$Site <- recode (spu_dataframe$Site, !!!Site_Names, .default = spu_dataframe$Site)
unique(unispec_field_key$Site) %>% sort()
df <- full_join(spu_dataframe, unispec_field_key) %>% arrange(DateTime) %>%
mutate_at(.vars = vars(Site, Block, Treatment), .funs = factor)
## SPECIFY SITE/DATE/ETC to ZOOM IN ON
check_site <- "LMATEDC"
check_date <- "2019-08-16" # necessary to unlist dates vector
## Files
first_file <- 0
last_file <- 600
# Select columns to Check
timedata <- df %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
select(Site, Date, DateTime, FileNum, Integration_ms, Type) %>%
group_by(DateTime) %>% distinct()
timedata$diff <- timedata$DateTime - lag(timedata$DateTime)
meta_timedata <- left_join(timedata, unispec_file_key)
time_check <- meta_timedata %>% select(Site, Date, DateTime, Block, Treatment, Replicate, FileNum, diff, Integration_ms, Type) %>% ungroup()
# Examine dataframe
time_check %>% print(n=300)
## SPECIFY SITE/DATE/ETC to ZOOM IN ON
check_site <- "LMATEDC"
check_date <- "2019-08-16" # necessary to unlist dates vector
## Files
first_file <- 0
last_file <- 600
# Select columns to Check
timedata <- df %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
select(Site, Date, DateTime, FileNum, Integration_ms, Type) %>%
group_by(DateTime) %>% distinct()
timedata$diff <- timedata$DateTime - lag(timedata$DateTime)
meta_timedata <- left_join(timedata, unispec_file_key)
unispec_file_key <- df %>%
select(spu_filename, Date, Site, Block, Treatment, Replicate, Location, FileNum, Notes, Weather, Type) %>%
mutate(key_fix = NA)
fix_keyname <- paste0(data_path, dir_year,"_unispec_file_key.csv")
write_csv(unispec_file_key, path = fix_keyname)
file_key_fix <- paste0(data_path, "2019_unispec_file_key.csv")
unispec_file_key_fix <- read_csv(file_key_fix, col_types = cols(
spu_filename = col_character(),
Date = col_character(), # for excel: col_date(format = "%m/%d/%Y"),
Site = col_character(),
Block = col_character(),
Treatment = col_character(),
Replicate = col_double(),
FileNum = col_double(),
Location = col_character(),
Weather = col_character(),
Notes = col_character(),
key_fix = col_logical()
)) %>% filter(!is.na(Site)) %>% mutate(Date = as.character(Date))
# Check for different spelling of site names
unique(spu_dataframe$Site)
spu_dataframe$Site <- recode (spu_dataframe$Site, !!!Site_Names, .default = spu_dataframe$Site)
df <- full_join(spu_dataframe, unispec_file_key_fix %>% select(-spu_filename, -Type)) %>% arrange(DateTime) %>%
mutate_at(.vars = vars(Site, Block, Treatment), .funs = factor)
## Summary Table
df %>%
group_by(Date, Site) %>%
summarize(Files = n_distinct(spu_filename)) %>%
kable()
## SPECIFY SITE/DATE/ETC to ZOOM IN ON
check_site <- "LMATEDC"
check_date <- "2019-08-16" # necessary to unlist dates vector
## Files
first_file <- 0
last_file <- 600
# Select columns to Check
timedata <- df %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
select(Site, Date, DateTime, FileNum, Integration_ms, Type) %>%
group_by(DateTime) %>% distinct()
timedata$diff <- timedata$DateTime - lag(timedata$DateTime)
meta_timedata <- left_join(timedata, unispec_file_key)
time_check <- meta_timedata %>% select(Site, Date, DateTime, Block, Treatment, Replicate, FileNum, diff, Integration_ms, Type) %>% ungroup()
# Examine dataframe
time_check %>% print(n=300)
# Select columns to Check
timedata <- df %>%
group_by(spu_filename) %>% distinct() %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
select(Site, Date, DateTime, FileNum, Integration_ms, Type) %>%
group_by(DateTime) %>% distinct()
timedata$diff <- timedata$DateTime - lag(timedata$DateTime)
meta_timedata <- left_join(timedata, unispec_file_key)
time_check <- meta_timedata %>% select(Site, Date, DateTime, Block, Treatment, Replicate, FileNum, diff, Integration_ms, Type) %>% ungroup()
# Examine dataframe
time_check %>% print(n=300)
# Select columns to Check
timedata <- df %>%
group_by(DateTime) %>% distinct() %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
select(Site, Date, DateTime, FileNum, Integration_ms, Type) %>%
group_by(DateTime) %>% distinct()
timedata$diff <- timedata$DateTime - lag(timedata$DateTime)
meta_timedata <- left_join(timedata, unispec_file_key)
time_check <- meta_timedata %>% select(Site, Date, DateTime, Block, Treatment, Replicate, FileNum, diff, Integration_ms, Type) %>% ungroup()
# Examine dataframe
time_check %>% print(n=300)
# Select columns to Check
timedata <- df %>%
group_by(DateTime) %>% unique() %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
select(Site, Date, DateTime, FileNum, Integration_ms, Type) %>%
group_by(DateTime) %>% distinct()
timedata$diff <- timedata$DateTime - lag(timedata$DateTime)
meta_timedata <- left_join(timedata, unispec_file_key)
# Select columns to Check
timedata <- df %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
select(Site, Date, DateTime, FileNum, Integration_ms, Type) %>%
group_by(DateTime) %>% unique()
timedata$diff <- timedata$DateTime - lag(timedata$DateTime)
meta_timedata <- left_join(timedata, unispec_file_key)
time_check <- meta_timedata %>% select(Site, Date, DateTime, Block, Treatment, Replicate, FileNum, diff, Integration_ms, Type) %>% ungroup()
# Examine dataframe
time_check %>% print(n=300)
?distinct()
# Select columns to Check
timedata <- df %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
select(Site, Date, DateTime, FileNum, Integration_ms, Type) %>%
distinct(DateTime)
timedata$diff <- timedata$DateTime - lag(timedata$DateTime)
meta_timedata <- left_join(timedata, unispec_file_key)
timedata
# Select columns to Check
timedata <- df %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
select(Site, Date, DateTime, FileNum, Integration_ms, Type) %>%
distinct(DateTime, .keep_all = T)
timedata$diff <- timedata$DateTime - lag(timedata$DateTime)
meta_timedata <- left_join(timedata, unispec_file_key)
time_check <- meta_timedata %>% select(Site, Date, DateTime, Block, Treatment, Replicate, FileNum, diff, Integration_ms, Type) %>% ungroup()
# Examine dataframe
time_check %>% print(n=300)
# Select columns to Check
timedata <- df %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
select(Site, Date, DateTime, FileNum, Integration_ms, Type) %>%
distinct(DateTime, .keep_all = T)
timedata
timedata$diff <- timedata$DateTime - lag(timedata$DateTime)
meta_timedata <- left_join(timedata, unispec_file_key)
meta_timedata
unispec_field_key
unispec_file_key <- df %>%
select(spu_filename, Date, Site, Block, Treatment, Replicate, Location, FileNum, Notes, Weather, Type) %>%
mutate(key_fix = NA) %>%
distinct(DateTime, .keep_all = T)
unispec_file_key <- df %>%
select(spu_filename, Date, Site, Block, Treatment, Replicate, Location, FileNum, Notes, Weather, Type) %>%
mutate(key_fix = NA) %>%
distinct(spu_filename, .keep_all = T)
fix_keyname <- paste0(data_path, dir_year,"_unispec_file_key.csv")
write_csv(unispec_file_key, path = fix_keyname)
file_key_fix <- paste0(data_path, "2019_unispec_file_key.csv")
unispec_file_key_fix <- read_csv(file_key_fix, col_types = cols(
spu_filename = col_character(),
Date = col_character(), # for excel: col_date(format = "%m/%d/%Y"),
Site = col_character(),
Block = col_character(),
Treatment = col_character(),
Replicate = col_double(),
FileNum = col_double(),
Location = col_character(),
Weather = col_character(),
Notes = col_character(),
key_fix = col_logical()
)) %>% filter(!is.na(Site)) %>% mutate(Date = as.character(Date))
# Check for different spelling of site names
unique(spu_dataframe$Site)
spu_dataframe$Site <- recode (spu_dataframe$Site, !!!Site_Names, .default = spu_dataframe$Site)
df <- full_join(spu_dataframe, unispec_file_key_fix %>% select(-spu_filename, -Type)) %>% arrange(DateTime) %>%
mutate_at(.vars = vars(Site, Block, Treatment), .funs = factor)
## SPECIFY SITE/DATE/ETC to ZOOM IN ON
check_site <- "LMATEDC"
check_date <- "2019-08-16" # necessary to unlist dates vector
## Files
first_file <- 0
last_file <- 600
# Select columns to Check
timedata <- df %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
select(Site, Date, DateTime, FileNum, Integration_ms, Type) %>%
distinct(DateTime, .keep_all = T)
timedata$diff <- timedata$DateTime - lag(timedata$DateTime)
meta_timedata <- left_join(timedata, unispec_file_key)
time_check <- meta_timedata %>% select(Site, Date, DateTime, Block, Treatment, Replicate, FileNum, diff, Integration_ms, Type) %>% ungroup()
# Examine dataframe
time_check %>% print(n=300)
## SPECIFY SITE/DATE/ETC to ZOOM IN ON
check_site <- "MAT"
check_date <- "2019-08-16" # necessary to unlist dates vector
## Files
first_file <- 0
last_file <- 600
# Select columns to Check
timedata <- df %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
select(Site, Date, DateTime, FileNum, Integration_ms, Type) %>%
distinct(DateTime, .keep_all = T)
timedata$diff <- timedata$DateTime - lag(timedata$DateTime)
meta_timedata <- left_join(timedata, unispec_file_key)
time_check <- meta_timedata %>% select(Site, Date, DateTime, Block, Treatment, Replicate, FileNum, diff, Integration_ms, Type) %>% ungroup()
# Examine dataframe
time_check %>% print(n=300)
# Examine dataframe
time_check %>% print(n=400)
## SPECIFY SITE/DATE/ETC to ZOOM IN ON
check_site <- "DHT"
## SPECIFY SITE/DATE/ETC to ZOOM IN ON
check_site <- "DHT"
check_date <- "2019-08-16" # necessary to unlist dates vector
## Files
first_file <- 0
last_file <- 600
# Select columns to Check
timedata <- df %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
select(Site, Date, DateTime, FileNum, Integration_ms, Type) %>%
distinct(DateTime, .keep_all = T)
timedata$diff <- timedata$DateTime - lag(timedata$DateTime)
meta_timedata <- left_join(timedata, unispec_file_key)
time_check <- meta_timedata %>% select(Site, Date, DateTime, Block, Treatment, Replicate, FileNum, diff, Integration_ms, Type) %>% ungroup()
# Examine dataframe
time_check %>% print(n=400)
first_file <- 0
last_file <- 15
data_check <- df %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file)
plot_check <- data_check %>%
unnest(Spectra) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
filter(Wavelength > 400, Wavelength < 1000) %>%
mutate(Reflectance = ChB/ChA) %>%
gather(key = Channel, value = Intensity, ChB, ChA) %>%
gather(key = ref_part, value = Reflectance_Intensity, Intensity, Reflectance)
## Plot Specified Correction Factors for quality check
plot_zoom <- ggplot(data = plot_check, mapping = aes(x = Wavelength, y = Reflectance_Intensity)) +
geom_line(aes(color=Integration_ms, linetype=Channel)) +
facet_grid(ref_part ~ Date + Site + FileNum + Integration_ms, scales="free")
plot_zoom
first_file <-215
last_file <- 235
data_check <- df %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file)
plot_check <- data_check %>%
unnest(Spectra) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
filter(Wavelength > 400, Wavelength < 1000) %>%
mutate(Reflectance = ChB/ChA) %>%
gather(key = Channel, value = Intensity, ChB, ChA) %>%
gather(key = ref_part, value = Reflectance_Intensity, Intensity, Reflectance)
## Plot Specified Correction Factors for quality check
plot_zoom <- ggplot(data = plot_check, mapping = aes(x = Wavelength, y = Reflectance_Intensity)) +
geom_line(aes(color=Integration_ms, linetype=Channel)) +
facet_grid(ref_part ~ Date + Site + FileNum + Integration_ms, scales="free")
plot_zoom
# Examine dataframe
time_check %>% print(n=400)
## SPECIFY SITE/DATE/ETC to ZOOM IN ON
check_site <- "MNAT"
check_date <- "2019-08-16" # necessary to unlist dates vector
## Files
first_file <- 0
last_file <- 600
# Select columns to Check
timedata <- df %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
select(Site, Date, DateTime, FileNum, Integration_ms, Type) %>%
distinct(DateTime, .keep_all = T)
timedata$diff <- timedata$DateTime - lag(timedata$DateTime)
meta_timedata <- left_join(timedata, unispec_file_key)
time_check <- meta_timedata %>% select(Site, Date, DateTime, Block, Treatment, Replicate, FileNum, diff, Integration_ms, Type) %>% ungroup()
# Examine dataframe
time_check %>% print(n=400)
## SPECIFY SITE/DATE/ETC to ZOOM IN ON
check_site <- "NANT"
check_date <- "2019-08-16" # necessary to unlist dates vector
## Files
first_file <- 0
last_file <- 600
# Select columns to Check
timedata <- df %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
select(Site, Date, DateTime, FileNum, Integration_ms, Type) %>%
distinct(DateTime, .keep_all = T)
timedata$diff <- timedata$DateTime - lag(timedata$DateTime)
meta_timedata <- left_join(timedata, unispec_file_key)
time_check <- meta_timedata %>% select(Site, Date, DateTime, Block, Treatment, Replicate, FileNum, diff, Integration_ms, Type) %>% ungroup()
# Examine dataframe
time_check %>% print(n=400)
first_file <-0
last_file <- 23
data_check <- df %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file)
plot_check <- data_check %>%
unnest(Spectra) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
filter(Wavelength > 400, Wavelength < 1000) %>%
mutate(Reflectance = ChB/ChA) %>%
gather(key = Channel, value = Intensity, ChB, ChA) %>%
gather(key = ref_part, value = Reflectance_Intensity, Intensity, Reflectance)
## Plot Specified Correction Factors for quality check
plot_zoom <- ggplot(data = plot_check, mapping = aes(x = Wavelength, y = Reflectance_Intensity)) +
geom_line(aes(color=Integration_ms, linetype=Channel)) +
facet_grid(ref_part ~ Date + Site + FileNum + Integration_ms, scales="free")
plot_zoom
# Examine dataframe
time_check %>% print(n=400)
field_key <- paste0(data_path, "2019_unispec_field_key.csv")
unispec_field_key <- read_csv(field_key, skip_empty_rows = T, col_types = cols(
Date = col_character(),
Site = col_character(),
Block = col_character(),
Treatment = col_character(),
Replicate = col_double(),
Location = col_character(),
FileNum = col_double(),
Weather = col_character(),
Notes = col_character()
)) ## remove NA rows
# Confirm spu_dataframe has same Site abbreviation as key
# > Standardize Site Names -----------------------------------------------------
# Check for different spelling of site names
unique(spu_dataframe$Site) %>% sort()
# spu_dataframe$Site <- recode (spu_dataframe$Site, !!!Site_Names, .default = spu_dataframe$Site)
unique(unispec_field_key$Site) %>% sort()
df <- full_join(spu_dataframe, unispec_field_key) %>% arrange(DateTime) %>%
mutate_at(.vars = vars(Site, Block, Treatment), .funs = factor)
unispec_file_key <- df %>%
select(spu_filename, Date, Site, Block, Treatment, Replicate, Location, FileNum, Notes, Weather, Type) %>%
mutate(key_fix = NA) %>%
distinct(spu_filename, .keep_all = T)
fix_keyname <- paste0(data_path, dir_year,"_unispec_file_key.csv")
write_csv(unispec_file_key, path = fix_keyname)
file_key_fix <- paste0(data_path, "2019_unispec_file_key.csv")
unispec_file_key_fix <- read_csv(file_key_fix, col_types = cols(
spu_filename = col_character(),
Date = col_character(), # for excel: col_date(format = "%m/%d/%Y"),
Site = col_character(),
Block = col_character(),
Treatment = col_character(),
Replicate = col_double(),
FileNum = col_double(),
Location = col_character(),
Weather = col_character(),
Notes = col_character(),
key_fix = col_logical()
)) %>% filter(!is.na(Site)) %>% mutate(Date = as.character(Date))
# Check for different spelling of site names
unique(spu_dataframe$Site)
spu_dataframe$Site <- recode (spu_dataframe$Site, !!!Site_Names, .default = spu_dataframe$Site)
df <- full_join(spu_dataframe, unispec_file_key_fix %>% select(-spu_filename, -Type)) %>% arrange(DateTime) %>%
mutate_at(.vars = vars(Site, Block, Treatment), .funs = factor)
## Summary Table
df %>%
group_by(Date, Site) %>%
summarize(Files = n_distinct(spu_filename)) %>%
kable()
## SPECIFY SITE/DATE/ETC to ZOOM IN ON
check_site <- "NANT"
check_date <- "2019-08-16" # necessary to unlist dates vector
## Files
first_file <- 0
last_file <- 600
# Select columns to Check
timedata <- df %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
select(Site, Date, DateTime, FileNum, Integration_ms, Type) %>%
distinct(DateTime, .keep_all = T)
timedata$diff <- timedata$DateTime - lag(timedata$DateTime)
meta_timedata <- left_join(timedata, unispec_file_key)
time_check <- meta_timedata %>% select(Site, Date, DateTime, Block, Treatment, Replicate, FileNum, diff, Integration_ms, Type) %>% ungroup()
# Examine dataframe
time_check %>% print(n=400)
## SPECIFY SITE/DATE/ETC to ZOOM IN ON
check_site <- "MNAT"
check_date <- "2019-08-16" # necessary to unlist dates vector
## Files
first_file <- 0
last_file <- 600
# Select columns to Check
timedata <- df %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
select(Site, Date, DateTime, FileNum, Integration_ms, Type) %>%
distinct(DateTime, .keep_all = T)
timedata$diff <- timedata$DateTime - lag(timedata$DateTime)
meta_timedata <- left_join(timedata, unispec_file_key)
time_check <- meta_timedata %>% select(Site, Date, DateTime, Block, Treatment, Replicate, FileNum, diff, Integration_ms, Type) %>% ungroup()
# Examine dataframe
time_check %>% print(n=400)
first_file <-0
last_file <- 23
data_check <- df %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file)
plot_check <- data_check %>%
unnest(Spectra) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
filter(Wavelength > 400, Wavelength < 1000) %>%
mutate(Reflectance = ChB/ChA) %>%
gather(key = Channel, value = Intensity, ChB, ChA) %>%
gather(key = ref_part, value = Reflectance_Intensity, Intensity, Reflectance)
## Plot Specified Correction Factors for quality check
plot_zoom <- ggplot(data = plot_check, mapping = aes(x = Wavelength, y = Reflectance_Intensity)) +
geom_line(aes(color=Integration_ms, linetype=Channel)) +
facet_grid(ref_part ~ Date + Site + FileNum + Integration_ms, scales="free")
plot_zoom
