Replicate = col_double(),
FileNum = col_double(),
Location = col_character(),
Weather = col_character(),
Notes = col_character(),
key_fix = col_logical()
)) %>% filter(!is.na(Site)) %>% mutate(Date = as.character(Date))
# Check for different spelling of site names
unique(spu_dataframe$Site)
spu_dataframe$Site <- recode (spu_dataframe$Site, !!!Site_Names, .default = spu_dataframe$Site)
df <- full_join(spu_dataframe, unispec_file_key_fix %>% select(-spu_filename, -Type)) %>% arrange(DateTime) %>%
mutate_at(.vars = vars(Site, Block, Treatment), .funs = factor)
## Summary Table
df %>%
group_by(Date, Site) %>%
summarize(Files = n_distinct(spu_filename)) %>%
kable()
## SPECIFY SITE/DATE/ETC to ZOOM IN ON
check_site <- "NANT"
check_date <- "2019-08-16" # necessary to unlist dates vector
## Files
first_file <- 0
last_file <- 600
# Select columns to Check
timedata <- df %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
select(Site, Date, DateTime, FileNum, Integration_ms, Type) %>%
distinct(DateTime, .keep_all = T)
timedata$diff <- timedata$DateTime - lag(timedata$DateTime)
meta_timedata <- left_join(timedata, unispec_file_key)
time_check <- meta_timedata %>% select(Site, Date, DateTime, Block, Treatment, Replicate, FileNum, diff, Integration_ms, Type) %>% ungroup()
# Examine dataframe
time_check %>% print(n=400)
## SPECIFY SITE/DATE/ETC to ZOOM IN ON
check_site <- "MNAT"
check_date <- "2019-08-16" # necessary to unlist dates vector
## Files
first_file <- 0
last_file <- 600
# Select columns to Check
timedata <- df %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
select(Site, Date, DateTime, FileNum, Integration_ms, Type) %>%
distinct(DateTime, .keep_all = T)
timedata$diff <- timedata$DateTime - lag(timedata$DateTime)
meta_timedata <- left_join(timedata, unispec_file_key)
time_check <- meta_timedata %>% select(Site, Date, DateTime, Block, Treatment, Replicate, FileNum, diff, Integration_ms, Type) %>% ungroup()
# Examine dataframe
time_check %>% print(n=400)
first_file <-0
last_file <- 23
data_check <- df %>%
filter(Date == check_date) %>%
filter(Site %in% check_site) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file)
plot_check <- data_check %>%
unnest(Spectra) %>%
filter(FileNum >= first_file) %>%
filter(FileNum <= last_file) %>%
filter(Wavelength > 400, Wavelength < 1000) %>%
mutate(Reflectance = ChB/ChA) %>%
gather(key = Channel, value = Intensity, ChB, ChA) %>%
gather(key = ref_part, value = Reflectance_Intensity, Intensity, Reflectance)
## Plot Specified Correction Factors for quality check
plot_zoom <- ggplot(data = plot_check, mapping = aes(x = Wavelength, y = Reflectance_Intensity)) +
geom_line(aes(color=Integration_ms, linetype=Channel)) +
facet_grid(ref_part ~ Date + Site + FileNum + Integration_ms, scales="free")
plot_zoom
getwd()
## File Key
unispec_sc_filekey <- read_csv(paste0(data_path, "2019-06-26_NDVI-comparison_Unispec-SC_filekey.csv"))
knitr::opts_chunk$set(echo = TRUE)
## Required Packages
library("tidyverse")
library("knitr")
data_path <- "C:/Users/toolik/Desktop/UnispecR/UnispecProtocol/spectral_instrument_comparison/"
data_path <- "/home/ruby/UnispecR/UnispecProtocol/spectral_instrument_comparison/"
band_defns <- tribble(
~definition, ~color, ~min, ~max,
"ITEX", "red", 560, 600,
"ITEX", "nir", 725, 1000,
"MODIS", "red", 620, 670,
"MODIS", "nir", 841, 876,
"MODIS", "blue", 459,479,
"SKYE", "red", 620, 680,
"SKYE", "nir", 830, 880,
"SKYE", "blue", 455, 480,
"Greenseeker", "red", 656, 656,
"Greenseeker", "nir", 774, 774,
"RapidSCAN", "red", 670, 670,
"RapidSCAN", "nir", 780, 780,
"RapidSCAN", "red_edge", 730, 730,
"ToolikGIS_Drone_2018", "red", 640, 680,
"ToolikGIS_Drone_2018", "nir", 820, 890,
"ToolikGIS_MicaSense_2019", "blue", 455, 495,
"ToolikGIS_MicaSense_2019", "green", 540, 580,
"ToolikGIS_MicaSense_2019", "red", 658, 678,
"ToolikGIS_MicaSense_2019", "red_edge", 707, 727,
"ToolikGIS_MicaSense_2019", "nir", 800, 880,
"ToolikEDC", "red", 560, 680,
"ToolikEDC", "nir", 725, 1000
)
read_spu_file_metadata <- function(filename) {
ruby_year <- str_detect(filename, "2017|2018|2019")
if (ruby_year) {
## Reads a .spu file from 2017 or 2018
# Filename metadata
filename_metadata <- unlist(str_split(filename, pattern = "/")) %>% last() %>% str_split("_") %>% unlist()
Site <- filename_metadata[2]
Date <- filename_metadata[1]
FileNum <- as.integer(str_extract(filename_metadata[3], "\\d{5}")) # extract 5 digits
# Extract info from the file itself, reading metadata from first 9 lines. Create a dataframe
text <- read_lines(filename, n_max=9)
DateTime <-  lubridate::mdy_hms(text[3], tz="America/Anchorage")
Date <- lubridate::date(DateTime)
Integration_ms <- as.numeric(strsplit(text[8], split = " ")[[1]][3])
Temp <- as.numeric(strsplit(strsplit(text[5], split = " ")[[1]][4], split="=")[[1]][2])
Remarks <- text[2]
# Truncated Filename
Spufilename <- unlist(str_split(filename, pattern = "/")) %>% last()
# Metadata
metaData <- tibble(Site=Site, FileNum=FileNum, Date=Date, DateTime=DateTime, Integration_ms=Integration_ms,
Temp=Temp, Remarks=Remarks, spu_filename=Spufilename )
} else {
## Reads a generic .spu file. Written for Historic (pre-2017) years.
# Extract metadata from filenames that have format "DATE/SITE_FILENUM.spu", e.g. "2018-06-22/DHT_00000.spu"
Site <- toupper(str_replace(filename,".*[/](.*)[_]+.*$","\\1")) # get string after / & before _
# Extract metadata from filenames that have format "DATESITEFILENUM.spu", e.g. "JUN8LOF100036.spu"
if (str_length(Site) > 5) {
Site <- toupper(str_replace(filename,"(^.*?\\d{1,2})\\s*([a-zA-Z]*)(\\d{5,7}\\.spu$)","\\2"))
# For 2012 and 2013 the spu filenames have ddmmmsite format; need to remove the 3 letter month.
if (str_length(Site)> 5){
pattern <- c("MAY","JUN","JUL", "AUG")
for (i in 1:4){Site<- sub(pattern[i], "", Site)}
}
}
# Avoid issues of digits in site/block name reading in as part of FileNum
## Based on the Unispec DC using 5 digits for automatic file numbering
FileNum <- as.integer(str_replace(filename,"(^.*?\\d{1,2})(\\D*)(\\d{5})(\\.spu$)","\\3"))
# Extract info from the file itself, reading metadata from first 9 lines. Create a dataframe
text <- read_lines(filename, n_max=9)
DateTime <-  lubridate::mdy_hms(text[3], tz="America/Anchorage")
Date <- lubridate::date(DateTime)
Integration_ms <- as.numeric(strsplit(text[8], split = " ")[[1]][3])
Temp <- as.numeric(strsplit(strsplit(text[5], split = " ")[[1]][4], split="=")[[1]][2])
Remarks <- text[2]
#Extract the file name in the spu file as a check. Some file names have spaces
Spufilename <- tolower(str_replace(text[1],".*[\\\\]([A-z0-9.]\\s*)","\\1"))
Spufilename <- str_replace(Spufilename,"\"","") # remove trailing quote
#Extract
Spufilename_file <- tolower(str_replace(filename,".*[\\\\/]([A-z0-9.]\\s*)","\\1"))
metaData <- tibble(Site=Site, FileNum=FileNum, Date=Date, DateTime=DateTime, Integration_ms=Integration_ms,
Temp=Temp, Remarks=Remarks, spu_filename=Spufilename )
}
print(Spufilename) # use for error checking
return(metaData)
}
read_spu_file_spectra <- function(filename) {
# For a generic .spu file regardless of name
# Read spectral intensity data into dataframe
data <- read.table(file = filename, skip = 9, col.names = c("Wavelength", "ChB", "ChA")) %>%
mutate(Reflectance = ChB/ChA)
# Only use the valid spectra
#  data_valid <-  subset(data, Wavelength > 400 & Wavelength < 1000)
return(data)
}
interpolate_spectra <- function(spectra) {
# interpolates unispec spectra to 1nm
# input: dataframe with Wavelength & Reflectance columns
# output: dataframe with Wavelength (every 1 nm) & Reflectance columns
#spectra <- spectra[[1]]
is.null(spectra)
interp <- approx(x = spectra$Wavelength, y = spectra$Reflectance,
xout = seq(400,1000, by = 1), method = "linear")
spectra_interp <- tibble(Wavelength = interp$x, Reflectance = interp$y)
return(spectra_interp)
}
calculate_spectral_bands <- function(spectra, band_defns, instruments) {
# Calculates spectral bands from dataframe including Wavelength & Reflectance
## inputs: spectra - Wavelength, Reflectance columns
##         band_defns : wavelengths definining colors
##         instrument : e.g. MODIS, SKYE, ITEX
##         bands   : the spectral bands to return, e.g. red, blue, nir, etc.
## output: spectra_bands = dataframe with Definition, Band, Averaged Reflectance
bands <- band_defns %>%
filter(definition %in% instruments)
# vector of wavelengths, one set per instrument
wavelengths <- seq(300, 1500, by = 1)
# dataframe of wavelengths labeled by instrument & color
bands_df <- tibble(Wavelength = rep(wavelengths, times = length(instruments)),
definition = rep(instruments, each = length(wavelengths))) %>%
full_join(bands) %>%
mutate(color_match = ifelse(Wavelength >= min & Wavelength <= max, color, NA)) %>%
select(Wavelength, definition, color_match) %>%
distinct()
## DATA: join to measured spectra
spectra_bands <- full_join(spectra, bands_df) %>%
group_by(definition, color_match) %>%
summarize(average_reflectance = mean(Reflectance)) %>%
filter(!is.na(color_match)) %>%
rename(band = color_match)
return(spectra_bands)
}
plot_spectra <- function(df_subset) {
# Plot spectra from a subset of a dataframe
plot_check <- df_subset %>%
unnest(Spectra) %>%
filter(Wavelength > 400, Wavelength < 1000) %>%
gather(key = Channel, value = Intensity, ChB, ChA) %>%
gather(key = ref_part, value = Reflectance_Intensity, Intensity, Reflectance)
## Plot Specified Correction Factors for quality check
plot_zoom <- ggplot(data = plot_check, mapping = aes(x = Wavelength, y = Reflectance_Intensity)) +
geom_line(aes(color=Channel)) +
facet_grid(ref_part ~ spu_filename, scales = "free")
#
# if("Treatment" %in% names(df_subset)) { # use for datafarmes with and without metadata
#   plot_zoom <- plot_zoom +
#     facet_grid(ref_part ~ DateTime + Site + FileNum + Treatment, scales="free")
#
# } else {
#   plot_zoom <- plot_zoom +
#     facet_grid(ref_part ~ DateTime + Site + FileNum, scales="free")
#
# }
return(plot_zoom)
}
## File Key (label scans)
unispec_dc_filekey <- read_csv(paste0(data_path, "2019-06-26_NDVI-comparison_Unispec-DC_filekey.csv"))
spu_filekey <- unispec_dc_filekey
## Read-in all files
spu_files <- list.files(path = data_path, pattern = ".spu$", full.names = T, recursive=T)
### read spu metadata : info from .spu header (Timestamp, Integration, Temp, Remarks)
spu_metadata <- map_dfr(spu_files, read_spu_file_metadata) %>%
mutate(spu_filename_full = spu_files)
### read actual spectra
spu_data <- spu_metadata %>%
mutate(Spectra=map(spu_filename_full, function(x) read_spu_file_spectra(x)))
## Standardize Dataframe
unispec_dc_data <- spu_data %>% select(spu_filename, Site, FileNum, Date, DateTime, Integration_ms, Temp, Remarks, Spectra, everything()) ## METADATA
unispec_dc_dataframe <- unispec_dc_filekey %>% full_join(unispec_dc_spectra) %>%
mutate(NOTES = as.character(NOTES))
## Datascans (not REFs)
### 2 column dataframe: (1) spu_filename; (2) Spectra <list column: dataframe w/Wavelength, ChA, ChB, Reflectance]
raw_spu_data <- unispec_dc_dataframe %>% select(FILENAME, Spectra) %>%
rename(spu_filename = FILENAME) %>% slice(7:113)
## REFscans
### 2 column dataframe: (1) spu_filename; (2) Spectra <list column: dataframe w/Wavelength, ChA, ChB, Reflectance]
ref_dataframe <- unispec_dc_dataframe %>% filter(str_detect(LOCATION,"REF")) %>% select(FILENAME, Spectra) %>%
rename(spu_filename = FILENAME)
## Calculate Correction Factors from REFs
ref_correction <- ref_dataframe %>% unnest(Spectra) %>%
mutate(CorrectionFactor = 1/Reflectance) %>%
group_by(Wavelength) %>%
summarize(CorrectionFactor = mean(CorrectionFactor), ref_filenames = str_c(spu_filename, collapse = ", "))
## Plot REFERENCES to check
ref_dataframe %>% plot_spectra() + ggtitle("REFscan spectra")
corrected_spu_data <- raw_spu_data %>% unnest(Spectra) %>%
left_join(ref_correction) %>%
mutate(Reflectance = Reflectance*CorrectionFactor) %>% ## update Reflectance w/ REF correction factor
nest(Wavelength, ChB, ChA, Reflectance, CorrectionFactor, .key = Spectra)
## Interpolated Datascans : to 1 nm resolution (Multispec Equivalent)
### only eeds "Spectra" column to include "Reflectance" column -- then it will work! >> UPDATE LATER TO INTERPOLATE ANY COLUMN?
unispec_dc_spectra <- corrected_spu_data %>% select(spu_filename, Spectra) %>%
rename(FILENAME = spu_filename) %>% ## to join with filekey
mutate(interpolated_spectra = map(Spectra, .f = interpolate_spectra)) # Spectra must have "Reflectance" column
corrected_spu_data <- raw_spu_data %>% unnest(Spectra) %>%
left_join(ref_correction) %>%
mutate(Reflectance = Reflectance*CorrectionFactor) %>% ## update Reflectance w/ REF correction factor
nest(Wavelength, ChB, ChA, Reflectance, CorrectionFactor, .key = Spectra)
## Plot REFERENCES to check
ref_dataframe %>% plot_spectra() + ggtitle("REFscan spectra")
## Datascans (not REFs)
### 2 column dataframe: (1) spu_filename; (2) Spectra <list column: dataframe w/Wavelength, ChA, ChB, Reflectance]
raw_spu_data <- unispec_dc_dataframe %>% select(FILENAME, Spectra) %>%
rename(spu_filename = FILENAME) %>% slice(7:113)
unispec_dc_dataframe <- unispec_dc_filekey %>% full_join(unispec_dc_spectra) %>%
mutate(NOTES = as.character(NOTES))
## Standardize Dataframe
unispec_dc_data <- spu_data %>% select(spu_filename, Site, FileNum, Date, DateTime, Integration_ms, Temp, Remarks, Spectra, everything()) ## METADATA
## Standardize Dataframe
unispec_dc_spectra <- spu_data %>% select(spu_filename, Site, FileNum, Date, DateTime, Integration_ms, Temp, Remarks, Spectra, everything()) ## METADATA
unispec_dc_spectra
unispec_dc_dataframe <- unispec_dc_filekey %>% full_join(unispec_dc_spectra) %>%
mutate(NOTES = as.character(NOTES))
## Datascans (not REFs)
### 2 column dataframe: (1) spu_filename; (2) Spectra <list column: dataframe w/Wavelength, ChA, ChB, Reflectance]
raw_spu_data <- unispec_dc_dataframe %>% select(FILENAME, Spectra) %>%
rename(spu_filename = FILENAME) %>% slice(7:113)
## Standardize Dataframe
unispec_dc_data <- spu_data %>% select(spu_filename, Site, FileNum, Date, DateTime, Integration_ms, Temp, Remarks, Spectra, everything()) ## METADATA
unispec_dc_dataframe <- unispec_dc_filekey %>% full_join(unispec_dc_data) %>%
mutate(NOTES = as.character(NOTES))
unispec_dc_filekey
unispec_dc_data
## Standardize Dataframe
unispec_dc_data <- spu_data %>% select(spu_filename, Site, FileNum, Date, DateTime, Integration_ms, Temp, Remarks, Spectra, everything()) %>%  ## METADATA
rename(FILENAME = spu_filename)
unispec_dc_dataframe <- unispec_dc_filekey %>% full_join(unispec_dc_data) %>%
mutate(NOTES = as.character(NOTES))
## Datascans (not REFs)
### 2 column dataframe: (1) spu_filename; (2) Spectra <list column: dataframe w/Wavelength, ChA, ChB, Reflectance]
raw_spu_data <- unispec_dc_dataframe %>% select(FILENAME, Spectra) %>%
rename(spu_filename = FILENAME) %>% slice(7:113)
## REFscans
### 2 column dataframe: (1) spu_filename; (2) Spectra <list column: dataframe w/Wavelength, ChA, ChB, Reflectance]
ref_dataframe <- unispec_dc_dataframe %>% filter(str_detect(LOCATION,"REF")) %>% select(FILENAME, Spectra) %>%
rename(spu_filename = FILENAME)
## Calculate Correction Factors from REFs
ref_correction <- ref_dataframe %>% unnest(Spectra) %>%
mutate(CorrectionFactor = 1/Reflectance) %>%
group_by(Wavelength) %>%
summarize(CorrectionFactor = mean(CorrectionFactor), ref_filenames = str_c(spu_filename, collapse = ", "))
## Plot REFERENCES to check
ref_dataframe %>% plot_spectra() + ggtitle("REFscan spectra")
corrected_spu_data <- raw_spu_data %>% unnest(Spectra) %>%
left_join(ref_correction) %>%
mutate(Reflectance = Reflectance*CorrectionFactor) %>% ## update Reflectance w/ REF correction factor
nest(Wavelength, ChB, ChA, Reflectance, CorrectionFactor, .key = Spectra)
## Interpolated Datascans : to 1 nm resolution (Multispec Equivalent)
### only eeds "Spectra" column to include "Reflectance" column -- then it will work! >> UPDATE LATER TO INTERPOLATE ANY COLUMN?
unispec_dc_spectra <- corrected_spu_data %>% select(spu_filename, Spectra) %>%
rename(FILENAME = spu_filename) %>% ## to join with filekey
mutate(interpolated_spectra = map(Spectra, .f = interpolate_spectra)) # Spectra must have "Reflectance" column
### R file format
write_rds(unispec_dc_spectra, paste0(data_path, "2019-06-26_NDVI-comparison_Unispec-DC_spectra.rds"))
### .csv file format (corrected, interpolated reflectance only)
spu_to_csv_data <-  unispec_dc_spectra %>% unnest(interpolated_spectra)
write_csv(spu_to_csv_data, paste0(data_path, "2019-06-26_NDVI-comparison_Unispec-DC_corrected-interpolated-reflectance.csv"))
#### RapidSCAN & Greenseeker DATA & KEY -------------
scanners <- read_csv(paste0(data_path, "2019-06-26_NDVI-comparison_RapidSCAN-Greenseeker_data.csv"))
## File Key
unispec_sc_filekey <- read_csv(paste0(data_path, "2019-06-26_NDVI-comparison_Unispec-SC_filekey.csv"))
## Data -- corrected with Multispec by EDC
unispec_sc_data <- read_csv(paste0(data_path, "2019-06-26_NDVI-comparison_Unispec-SC_data.csv"), skip = 1, col_names = T) %>%
select(-X9) %>% # remove empty column
rename(Height = `Instrument Height (m)`, FILENAME = `File Name`) %>%
gather(key = Wavelength, value = Reflectance, `310`:`1130`) %>%  ## METADATA
mutate(Wavelength = as.integer(Wavelength))
unispec_sc_spectra <- unispec_sc_data %>% group_by(FILENAME) %>%
nest(Wavelength, Reflectance, .key = Spectra) ## to join with filekey
## Calculate NDVI
unispec_sc_dataframe <- unispec_sc_filekey %>% full_join(unispec_sc_spectra) %>%
mutate(Bands = map(Spectra, function(x) calculate_spectral_bands(x, band_defns = band_defns, instruments = c("ToolikEDC", "MODIS", "Greenseeker", "RapidSCAN"))))
## File Key
unispec_dc_filekey <- read_csv(paste0(data_path, "2019-06-26_NDVI-comparison_Unispec-DC_filekey.csv"))
## Data (.csv saved post R-processing to correct w/White REF & interpolate to 1nm)
unispec_dc_all_data <- read_rds(paste0(data_path, "2019-06-26_NDVI-comparison_Unispec-DC_spectra.rds"))
unispec_dc_spectra <- read_csv(paste0(data_path, "2019-06-26_NDVI-comparison_Unispec-DC_corrected-interpolated-reflectance.csv")) %>%
group_by(FILENAME) %>%
nest(Wavelength, Reflectance, .key = Spectra) ## to join with filekey
# Calculate Spectral Bands
unispec_dc_dataframe <- unispec_dc_spectra %>%
left_join(unispec_dc_filekey)
unispec_dc_dataframe
## File Key
asd_filekey <- read_csv(paste0(data_path, "2019-06-26_NDVI-comparison_ASD_filekey.csv"))
## Data
asd_spectra <- read_csv(paste0(data_path, "2019-06-26_NDVI-comparison_ASD_data.csv"), col_names = T) %>%
gather(2:94, key = FILENAME, value = Reflectance) %>%
rename(Wavelength = 1) %>%
group_by(FILENAME) %>% nest(Wavelength, Reflectance, .key = Spectra)
asd_dataframe <- asd_filekey %>%
full_join(asd_spectra) %>%  mutate(NOTES = as.character(NOTES)) %>%
mutate(Bands = map(Spectra, function(x) calculate_spectral_bands(x, band_defns = band_defns, instruments = c("ToolikEDC", "MODIS", "Greenseeker", "RapidSCAN"))))
unispec_sc_dataframe
unispec_sc_dataframe$Bands[1]
unispec_dc_dataframe
## Calculate Spectral Bands for Multispectral Instruments
multispectral_df <- bind_rows(unispec_sc_dataframe, unispec_dc_dataframe) %>%
bind_rows(asd_dataframe) %>%
mutate(Bands = map(Spectra, function(x) calculate_spectral_bands(x, band_defns = band_defns, instruments = c("ToolikEDC", "MODIS", "Greenseeker", "RapidSCAN"))))
## Recode LOCATION variable to be Human-Readable
multispec_df <- multispectral_df %>% mutate(LOCATION_LONG = LOCATION)
Location_Names <- list(`LMAT_B2_CT_EDC_2-1` = "T1",
`LMAT_B2_CT_EDC_2-2` = "T2",
`LMAT_B2_CT_EDC_2-3` = "T3",
`LMAT_B2_F10_15m` = "S1",
`LMAT_B2_F10_10m` = "S2",
`LMAT_B2_F10_5m` = "S3",
`ITEX_BOARDWALK-1` = "H1",
`ITEX_BOARDWALK-2` = "H2",
`ITEX_BOARDWALK-3` = "H3")
multispec_df
multispec_df$Bands[1]
getwd()
# Write this to .rds dataframe to read-in later
write_rds(multispec_df, "spec_synthesis_multispec_band_df.rds"
# Write this to .rds dataframe to read-in later
write_rds(multispec_df, "spec_synthesis_multispec_band_df.rds")
# Write this to .rds dataframe to read-in later
write_rds(multispec_df, "spec_synthesis_multispec_band_df.rds")
getwd()
write_rds(multispec_df, "UnispecProtocol/spectral_instrument_comparison/spec_synthesis_multispec_band_df.rds")
# Write this to .rds dataframe to read-in later
multispec_bands_name <- "UnispecProtocol/spectral_instrument_comparison/spec_synthesis_multispec_band_df.rds"
multispec_df <- read_rds(multispec_bands_name)
multispec_df
multispec_df_plot <- multispec_df %>% unnest(Spectra) %>%
filter(nchar(LOCATION) == 2) %>% # exclude whole plot Unispec-DC and ASD measurements
filter(Wavelength > 300, Wavelength < 1000)
ggplot(data = multispec_df_plot, aes(x = Wavelength, y = Reflectance)) +
geom_line(aes(color = INSTRUMENT, group = FILENAME)) +
facet_wrap(vars(LOCATION))
multispec_df_plot
multispec_df
## Recode LOCATION variable to be Human-Readable
multispec_df <- multispectral_df %>% mutate(LOCATION_LONG = LOCATION)
Location_Names <- list(`LMAT_B2_CT_EDC_2-1` = "T1",
`LMAT_B2_CT_EDC_2-2` = "T2",
`LMAT_B2_CT_EDC_2-3` = "T3",
`LMAT_B2_F10_15m` = "S1",
`LMAT_B2_F10_10m` = "S2",
`LMAT_B2_F10_5m` = "S3",
`ITEX_BOARDWALK-1` = "H1",
`ITEX_BOARDWALK-2` = "H2",
`ITEX_BOARDWALK-3` = "H3")
multispec_df$LOCATION <- recode (multispec_df$LOCATION_LONG, !!!Location_Names, .default = multispec_df$LOCATION)
scanners$LOCATION <- recode(scanners$LOCATION, !!!Location_Names, .default = scanners$LOCATION)
# Write this to .rds dataframe to read-in later
multispec_bands_name <- "UnispecProtocol/spectral_instrument_comparison/spec_synthesis_multispec_band_df.rds"
write_rds(multispec_df, multispec_bands_name)
multispec_df <- read_rds(multispec_bands_name)
multispec_df_plot <- multispec_df %>% unnest(Spectra) %>%
filter(nchar(LOCATION) == 2) %>% # exclude whole plot Unispec-DC and ASD measurements
filter(Wavelength > 300, Wavelength < 1000)
ggplot(data = multispec_df_plot, aes(x = Wavelength, y = Reflectance)) +
geom_line(aes(color = INSTRUMENT, group = FILENAME)) +
facet_wrap(vars(LOCATION))
str(multispec_df)
multispec_df$LOCATION %>% factor()
multispec_df$LOCATION %>% factor() %>% levels()
multispec_df %>% filter(nchar(LOCATION > 2))
multispec_df %>% filter(nchar(LOCATION) > 2)
?is.finite()
is.finite(NaN)
field_key <- paste0(data_path, "2019_unispec_field_key.csv")
unispec_field_key <- read_csv(field_key, skip_empty_rows = T, col_types = cols(
Date = col_character(),
Site = col_character(),
Block = col_character(),
Treatment = col_character(),
Replicate = col_double(),
Location = col_character(),
FileNum = col_double(),
Weather = col_character(),
Notes = col_character()
)) ## remove NA rows
data_path <- "UnispecRecord/UnispecData/2019/"
## for Ruby's chromebook
data_path <- "UnispecRecord/UnispecData/2019/"
dir_year <- "2019"
knitr::opts_chunk$set(echo = TRUE)
## Required Packages
library("tidyverse")
library("knitr")
source("UnispecProtocol/unispec_protocol_functions.R") # file loads required functions
## Data Path
data_path <-  "/Users/toolik/OneDrive - Marine Biological Laboratory/Toolik Terrestrial/UnispecData/2019/"
## for Ruby's chromebook
data_path <- "UnispecRecord/UnispecData/2019/"
dir_year <- "2019"
Site_Names <- list(DHT = "DHT", DH ="DHT", LDHT = "DHT", DHTB = "DHT", HTH = "DHT", DHTPC = "DHT", HST = "HIST", HIS="HIST",
LOF = "LMAT",  LOFB = "LMAT", LNB = "LMAT", LOFRB ="LMAT",
MATB="MAT", MATSL= "MAT", MATBK = "MAT",
MANTB ="MNAT",MNATB ="MNAT", NAMTB = "MNAT",
NMNT = "NANT", NANTB ="NANT", JULNB ="NANT",NMNTB ="NANT",
LSHB= "SHB", SHBB = "SHB", SHRBB = "SHB", SHRB = "SHB",
LWSG = "WSG", WSGB = "WSG", WS ="WSG", WSB = "WSG", WSDB = "WSG") #TEST = "LAB2"
band_defns <- tribble(
~definition, ~color, ~min, ~max,
"ITEX", "red", 560, 600,
"ITEX", "nir", 725, 1000,
"MODIS", "red", 620, 670,
"MODIS", "nir", 841, 876,
"MODIS", "blue", 459,479,
"SKYE", "red", 620, 680,
"SKYE", "nir", 830, 880,
"SKYE", "blue", 455, 480,
"ToolikGIS_Drone_2018", "red", 640, 680,
"ToolikGIS_Drone_2018", "nir", 820, 890,
"ToolikGIS_MicaSense_2019", "blue", 455, 495,
"ToolikGIS_MicaSense_2019", "green", 540, 580,
"ToolikGIS_MicaSense_2019", "red", 658, 678,
"ToolikGIS_MicaSense_2019", "red_edge", 707, 727,
"ToolikGIS_MicaSense_2019", "near_ir", 800, 880,
"ToolikEDC", "red", 560, 680,
"ToolikEDC", "nir", 725, 1000
)
## for Ruby's chromebook
data_path <- "UnispecRecord/UnispecData/2019/"
field_key <- paste0(data_path, "2019_unispec_field_key.csv")
unispec_field_key <- read_csv(field_key, skip_empty_rows = T, col_types = cols(
Date = col_character(),
Site = col_character(),
Block = col_character(),
Treatment = col_character(),
Replicate = col_double(),
Location = col_character(),
FileNum = col_double(),
Weather = col_character(),
Notes = col_character()
)) ## remove NA rows
unique(spu_dataframe$Site) %>% sort()
# spu_dataframe$Site <- recode (spu_dataframe$Site, !!!Site_Names, .default = spu_dataframe$Site)
unique(unispec_field_key$Site) %>% sort()
