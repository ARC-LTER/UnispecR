WSG <- c("WSG1", "WSG23", "WSG")
site_list <- list("MAT", "LMAT", "MNAT", "NANT", "DHT", WSG, SHB, "HST")
CT <- c("CT","CT1","CT2")
NP <- c("F0.5","F1","F2","F5","F10","NP", "NO3", "NH4")
trtmt_list <- list(CT, "N", "P", NP)
# Find all file keys
key_files <- list.files(path = data_path, pattern = "*_key.csv*", full.names = T, recursive = T)
getwd()
utils::getSrcDirectory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
dirname(rstudioapi::getActiveDocumentContext()$path)
# REQUIRED PACKAGES -------------------------------------------------------
require(tidyverse)
require(stringr)
require(lubridate)
# Directory -----------------------------------------------------------
data_path <- "Toolik-Summer-data/Unispec/Multispec/2017"
read_multispec_file <- function(multi_file) {
## Reads single multispec generated file
## Parses file name for usable info, format: SITE_{YEAR-MONTH-DAY}_TYPE.csv
## Reads in metadata from first 5 lines
## Reads in reflectance data (400-1100nm Wavelengths) from following lines
type <- str_extract(multi_file, "raw|correct")
date <- ymd(str_extract(multi_file, "[\\d]{4}[-][\\d]+[-][\\d]+")) # regex for date
meta <- read_lines(multi_file, n_max=5, skip=0)
### Comma separated values:
## Line 1 - reference files (if corrected)
## Line 2 - list of .spu files.
## Line 3 - date # NOT ACCURATE
## Line 4 - time # NOT ACCURATE, multispec does something weird to times. In raw .spu files, they are accurate.
## Line 5 - temp / wind? # NOT USED
ref_files <- str_split(meta[1], pattern=",")[[1]]
spu_files <- str_split(meta[2], pattern=",")[[1]][-1] #Unlist & remove "Wavelength" to get list of data files
site <- str_extract(spu_files, "^(.*?)(?=_)") #str_split(spu_files, "_")[[1]][1]
fileNums <- as.numeric(str_extract(spu_files, "[\\d]{4,5}"))
#dates <- str_trim(str_split(meta[3], pattern=",")[[1]][-1])
#times <- str_split(meta[4], pattern=",")[[1]][-1]
## Parsing file name into variables, tag with type and date
site_fileNum_type_date <- str_c(site, fileNums, type, date, sep = "_")
## Read in what the file looks like, metadata in column name
multi_file_df <- read_csv(file = multi_file, skip = 6,
col_names = c("Wavelength", site_fileNum_type_date),
col_types = cols(
.default = col_double(),
Wavelength = col_integer()))
## Tidy up data frame
tidy_df <- multi_file_df %>%
gather(-Wavelength, key = "site_fileNum_type_date", value = "Reflectance") %>%
separate(site_fileNum_type_date, into = c("Site", "FileNum", "Type", "Date"), sep = "_", convert = T) %>%
mutate(Date = ymd(Date))
return(tidy_df)
}
read_key_file <- function(key_file) {
# Read in format of .csv
key_csv <- read_csv(file = key_file, col_names = T,
col_types = cols(
Site = col_character(),
Block = col_character(),
Treatment = col_character(),
Date = col_character(),
Measurement1 = col_integer(),
Measurement2 = col_integer(),
Measurement3 = col_integer(),
Measurement4 = col_integer(),
Measurement5 = col_integer(),
Weather = col_character(),
Notes = col_character()
))
# Consolidate measurements to tidy dataframe
key_df <- key_csv %>%
gather(Measurement, FileNum, Measurement1:Measurement5) %>%
filter(!is.na(FileNum)) %>%
mutate(Measurement = str_sub(Measurement, 12, 12)) %>%
mutate(Date = lubridate::mdy(Date))
return(key_df)
}
getwd()
# REQUIRED PACKAGES -------------------------------------------------------
require(tidyverse)
require(stringr)
require(lubridate)
require(tcltk2)
# REQUIRED PACKAGES -------------------------------------------------------
require(tidyverse)
require(stringr)
require(lubridate)
require(openxlsx)
require(tcltk2)
read.processedfile <- function(filename) {
# Read the first 21 rows of the "spectra" sheet to get the metadata for the spu files
df_spectra <- read.xlsx(xlsxFile = filename, sheet = "Spectra", skipEmptyRows = T, rows = 1:21, detectDates = F) %>%
gather(columX,valname,-Reflectance) %>%
spread(Reflectance,valname)%>%                # Transposed the first row to column variables
rename(Spufilename = Wavelength, Research_location = SITE, Site = EXPERIMENT, Date = DATE, Block = BLOCK,
Time = TIME, Treatment = TREATMENT) %>%  # Rename the columns
select (-YEAR, -columX) %>%
select_all(~gsub("\\s+|\\.", "", .)) %>%        # remove spaces from column names
select( Research_location, Date, Time, Block, Site, Treatment, REP, Spufilename, 'NDVI(MODIS)',
'EVI(MODIS)', 'EVI2(MODIS)','PRI(550Reference)', 'PRI(570Ref)',
'WBI','ChlIndex')
# Read first 30 rows of Notes sheet to get the metadata from a processed file
df_references <- read.xlsx(xlsxFile = filename, sheet = "Notes", skipEmptyRows = T, rows = 1:30) %>%
gather(columnx,valname, -Summary.Information) %>%
spread(Summary.Information,valname) %>%        # Transposed the first row to column variables
rename(Research_location = SITE, Date = 'Date Collected',Spufilename ='White Panel Reflectance File Used',   #rename them to match df_specra
Site = 'LTER Experiment',Experiment = EXPERIMENT, Block = BLOCK,
Weather = 'Brief Weather Description', Time = 'Approximate Time of Collection')  %>%
mutate (Research_location = Research_location[1], Date = Date[1], Time = Time[1], Site = Site[1],
Block = NA, Treatment = paste0("REF",row.names(.))) %>%
select (Research_location, Date, Time, Site, Block, Treatment, Spufilename, Weather) %>%
unnest(Spufilename = strsplit(Spufilename, "\\s*,\\s*")) %>%  # Spufilenames can be a comma delimited string of files; create a row for each
mutate (Spufilename = ifelse(".spu" %in% Spufilename, Spufilename,paste0(tolower(Spufilename),".spu")))
# Append the references spectra to the measured spectra
df_all <-bind_rows(df_references,df_spectra)
df_all <- df_all %>%
mutate(Date = convertToDate(Date,tz ="America/Anchorage"),   #convert excel data to date
Spufilename = tolower(Spufilename),
FileNum = as.integer(str_replace(Spufilename,"(^.*?\\d{1,2})(\\D*)(\\d{5,6})(\\.spu$)","\\3")),
#FileNum = as.integer(str_extract(Spufilename, "[0-9]{5}")),
Process_file = filename)
return(df_all)
}
read.spufile.metadata <- function(filename) {
#read metadata from first 9 lines and create a dataframe
text <- read_lines(filename, n_max=9)
# Extract metadata from filenames that have format "DATE/SITE_FILENUM.spu", e.g. "2018-06-22/DHT_00000.spu"
Site <- str_replace(filename,".*[/](.*)[_]+.*$","\\1") # get string after / & before _
# Extract metadata from filenames that have format "DATESITEFILENUM.spu", e.g. "JUN8LOF100036.spu"
if (str_length(Site) > 5)
{Site <- str_replace(filename,"(^.*?\\d{1,2})(\\D*)(\\d{5,6}\\.spu$)","\\2")}
FileNum <- as.integer(str_extract(filename, "[0-9]{5,6}"))
# Extract unfo from the file itself
DateTime <-  lubridate::mdy_hms(text[3], tz="America/Anchorage")
Integration_ms <- as.numeric(strsplit(text[8], split = " ")[[1]][3])
Temp <- as.numeric(strsplit(strsplit(text[5], split = " ")[[1]][4], split="=")[[1]][2])
Remarks <- text[2]
Spufilename <- tolower(str_replace(text[1],".*[\\\\]([A-z0-9.]*).*$","\\1")) #Extract the file name in the file as a check
metaData <- data_frame(Site=Site, FileNum=FileNum, DateTime=DateTime, Integration_ms=Integration_ms,
Temp=Temp, Remarks=Remarks, Spufilename=Spufilename )
return(metaData)
}
setwd(tk_choose.dir("./","choose working directory."))
getwd()
file_names <- list.files('.', full.names= F, pattern='*.xlsx', recursive=FALSE)
#xlsx files - read key info from the processed data.
key_info <- map_dfr(file_names,function (x) read.processedfile (x), .id = "process_file")
# Check for different spelling of site names
unique(key_info$Site)
# Recode them to stadard ones.
Site_Names <- list(Hist="HIST", LOF = "LMAT")
key_info$Site <- recode (key_info$Site, !!!Site_Names, .default = key_info$Site)
# check data
check_df <- subset(key_info,is.na(key_info$FileNum))
View(check_df)
read.processedfile <- function(filename) {
# Read the first 21 rows of the "spectra" sheet to get the metadata for the spu files
df_spectra <- read.xlsx(xlsxFile = filename, sheet = "Spectra", skipEmptyRows = T, rows = 1:21, detectDates = F) %>%
gather(columX,valname,-Reflectance) %>%
spread(Reflectance,valname)%>%                # Transposed the first row to column variables
rename(Spufilename = Wavelength, Research_location = SITE, Site = EXPERIMENT, Date = DATE, Block = BLOCK,
Time = TIME, Treatment = TREATMENT) %>%  # Rename the columns
select (-YEAR, -columX) %>%
select_all(~gsub("\\s+|\\.", "", .)) %>%        # remove spaces from column names
select( Research_location, Date, Time, Block, Site, Treatment, REP, Spufilename, 'NDVI(MODIS)',
'EVI(MODIS)', 'EVI2(MODIS)','PRI(550Reference)', 'PRI(570Ref)',
'WBI','ChlIndex')
# Read first 30 rows of Notes sheet to get the metadata from a processed file
df_references <- read.xlsx(xlsxFile = filename, sheet = "Notes", skipEmptyRows = T, rows = 1:30) %>%
gather(columnx,valname, -Summary.Information) %>%
spread(Summary.Information,valname) %>%        # Transposed the first row to column variables
rename(Research_location = SITE, Date = 'Date Collected',Spufilename ='White Panel Reflectance File Used',   #rename them to match df_specra
Site = 'LTER Experiment',Experiment = EXPERIMENT, Block = BLOCK,
Weather = 'Brief Weather Description', Time = 'Approximate Time of Collection')  %>%
mutate (Research_location = Research_location[1], Date = Date[1], Time = Time[1], Site = Site[1],
Block = NA, Treatment = paste0("REF",row.names(.))) %>%
select (Research_location, Date, Time, Site, Block, Treatment, Spufilename, Weather) %>%
unnest(Spufilename = strsplit(Spufilename, "\\s*,\\s*")) %>%  # Spufilenames can be a comma delimited string of files; create a row for each
mutate (Spufilename = ifelse("spu" %in% Spufilename, Spufilename,paste0(tolower(Spufilename),".spu")))
# Append the references spectra to the measured spectra
df_all <-bind_rows(df_references,df_spectra)
df_all <- df_all %>%
mutate(Date = convertToDate(Date,tz ="America/Anchorage"),   #convert excel data to date
Spufilename = tolower(Spufilename),
FileNum = as.integer(str_replace(Spufilename,"(^.*?\\d{1,2})(\\D*)(\\d{5,6})(\\.spu$)","\\3")),
#FileNum = as.integer(str_extract(Spufilename, "[0-9]{5}")),
Process_file = filename)
return(df_all)
}
#xlsx files - read key info from the processed data.
key_info <- map_dfr(file_names,function (x) read.processedfile (x), .id = "process_file")
# Check for different spelling of site names
unique(key_info$Site)
# Recode them to stadard ones.
Site_Names <- list(Hist="HIST", LOF = "LMAT")
key_info$Site <- recode (key_info$Site, !!!Site_Names, .default = key_info$Site)
# check data
check_df <- subset(key_info,is.na(key_info$FileNum))
View(check_df)
read.processedfile <- function(filename) {
# Read the first 21 rows of the "spectra" sheet to get the metadata for the spu files
df_spectra <- read.xlsx(xlsxFile = filename, sheet = "Spectra", skipEmptyRows = T, rows = 1:21, detectDates = F) %>%
gather(columX,valname,-Reflectance) %>%
spread(Reflectance,valname)%>%                # Transposed the first row to column variables
rename(Spufilename = Wavelength, Research_location = SITE, Site = EXPERIMENT, Date = DATE, Block = BLOCK,
Time = TIME, Treatment = TREATMENT) %>%  # Rename the columns
select (-YEAR, -columX) %>%
select_all(~gsub("\\s+|\\.", "", .)) %>%        # remove spaces from column names
select( Research_location, Date, Time, Block, Site, Treatment, REP, Spufilename, 'NDVI(MODIS)',
'EVI(MODIS)', 'EVI2(MODIS)','PRI(550Reference)', 'PRI(570Ref)',
'WBI','ChlIndex')
# Read first 30 rows of Notes sheet to get the metadata from a processed file
df_references <- read.xlsx(xlsxFile = filename, sheet = "Notes", skipEmptyRows = T, rows = 1:30) %>%
gather(columnx,valname, -Summary.Information) %>%
spread(Summary.Information,valname) %>%        # Transposed the first row to column variables
rename(Research_location = SITE, Date = 'Date Collected',Spufilename ='White Panel Reflectance File Used',   #rename them to match df_specra
Site = 'LTER Experiment',Experiment = EXPERIMENT, Block = BLOCK,
Weather = 'Brief Weather Description', Time = 'Approximate Time of Collection')  %>%
mutate (Research_location = Research_location[1], Date = Date[1], Time = Time[1], Site = Site[1],
Block = NA, Treatment = paste0("REF",row.names(.))) %>%
select (Research_location, Date, Time, Site, Block, Treatment, Spufilename, Weather) %>%
unnest(Spufilename = strsplit(Spufilename, "\\s*,\\s*")) %>%  # Spufilenames can be a comma delimited string of files; create a row for each
mutate (test= ("spu" %in% Spufilename)) %>%
mutate (Spufilename = ifelse("spu" %in% Spufilename, Spufilename,paste0(tolower(Spufilename),".spu")))
# Append the references spectra to the measured spectra
df_all <-bind_rows(df_references,df_spectra)
df_all <- df_all %>%
mutate(Date = convertToDate(Date,tz ="America/Anchorage"),   #convert excel data to date
Spufilename = tolower(Spufilename),
FileNum = as.integer(str_replace(Spufilename,"(^.*?\\d{1,2})(\\D*)(\\d{5,6})(\\.spu$)","\\3")),
#FileNum = as.integer(str_extract(Spufilename, "[0-9]{5}")),
Process_file = filename)
return(df_all)
}
key_info$Site <- recode (key_info$Site, !!!Site_Names, .default = key_info$Site)
# check data
check_df <- subset(key_info,is.na(key_info$FileNum))
View(check_df)
View(key_info)
check_df <- check_df %>% mutate (test= ("spu" %in% Spufilename))
View(check_df)
check_df <- check_df %>% mutate (str_detect("spu" %in% Spufilename))
check_df <- check_df %>% mutate (str_detect("spu", Spufilename))
View(check_df)
check_df <- check_df %>% mutate (str_detect(Spufilename,"spu"))
View(check_df)
check_df <- check_df %>% mutate_if (test = str_detect(Spufilename,"spu"),paste0(tolower(Spufilename),".test"))
View(check_df)
check_df <- check_df %>% mutate_if (str_detect(Spufilename,"spu"),test =paste0(tolower(Spufilename),".test"))
check_df <- check_df %>% mutate(test = str_detect(Spufilename,"spu"),paste0(tolower(Spufilename),".test"))
View(check_df)
check_df <- check_df %>% mutate(test = ifelse(str_detect(Spufilename,"spu"),paste0(tolower(Spufilename),".test"),test = )
check_df <- check_df %>% mutate(test = ifelse(str_detect(Spufilename,"spu"),paste0(tolower(Spufilename),".test"),test )
)
View(check_df)
read.processedfile <- function(filename) {
# Read the first 21 rows of the "spectra" sheet to get the metadata for the spu files
df_spectra <- read.xlsx(xlsxFile = filename, sheet = "Spectra", skipEmptyRows = T, rows = 1:21, detectDates = F) %>%
gather(columX,valname,-Reflectance) %>%
spread(Reflectance,valname)%>%                # Transposed the first row to column variables
rename(Spufilename = Wavelength, Research_location = SITE, Site = EXPERIMENT, Date = DATE, Block = BLOCK,
Time = TIME, Treatment = TREATMENT) %>%  # Rename the columns
select (-YEAR, -columX) %>%
select_all(~gsub("\\s+|\\.", "", .)) %>%        # remove spaces from column names
select( Research_location, Date, Time, Block, Site, Treatment, REP, Spufilename, 'NDVI(MODIS)',
'EVI(MODIS)', 'EVI2(MODIS)','PRI(550Reference)', 'PRI(570Ref)',
'WBI','ChlIndex')
# Read first 30 rows of Notes sheet to get the metadata from a processed file
df_references <- read.xlsx(xlsxFile = filename, sheet = "Notes", skipEmptyRows = T, rows = 1:30) %>%
gather(columnx,valname, -Summary.Information) %>%
spread(Summary.Information,valname) %>%        # Transposed the first row to column variables
rename(Research_location = SITE, Date = 'Date Collected',Spufilename ='White Panel Reflectance File Used',   #rename them to match df_specra
Site = 'LTER Experiment',Experiment = EXPERIMENT, Block = BLOCK,
Weather = 'Brief Weather Description', Time = 'Approximate Time of Collection')  %>%
mutate (Research_location = Research_location[1], Date = Date[1], Time = Time[1], Site = Site[1],
Block = NA, Treatment = paste0("REF",row.names(.))) %>%
select (Research_location, Date, Time, Site, Block, Treatment, Spufilename, Weather) %>%
unnest(Spufilename = strsplit(Spufilename, "\\s*,\\s*")) %>%  # Spufilenames can be a comma delimited string of files; create a row for each
mutate (test= str_detect(Spufilename, ".spu")) %>%
mutate (Spufilename =ifelse(str_detect(Spufilename,".spu"), Spufilename, paste0(tolower(Spufilename),".spu")))
# Append the references spectra to the measured spectra
df_all <-bind_rows(df_references,df_spectra)
df_all <- df_all %>%
mutate(Date = convertToDate(Date,tz ="America/Anchorage"),   #convert excel data to date
Spufilename = tolower(Spufilename),
FileNum = as.integer(str_replace(Spufilename,"(^.*?\\d{1,2})(\\D*)(\\d{5,6})(\\.spu$)","\\3")),
#FileNum = as.integer(str_extract(Spufilename, "[0-9]{5}")),
Process_file = filename)
return(df_all)
}
#xlsx files - read key info from the processed data.
key_info <- map_dfr(file_names,function (x) read.processedfile (x), .id = "process_file")
# Check for different spelling of site names
unique(key_info$Site)
# Recode them to stadard ones.
Site_Names <- list(Hist="HIST", LOF = "LMAT")
key_info$Site <- recode (key_info$Site, !!!Site_Names, .default = key_info$Site)
# check data
check_df <- subset(key_info,is.na(key_info$FileNum))
View(check_df)
#xlsx files - read key info from the processed data.
key_info <- map_dfr(file_names,function (x) read.processedfile (x), .id = "process_file")
# Check for different spelling of site names
unique(key_info$Site)
# Recode them to stadard ones.
Site_Names <- list(Hist="HIST", LOF = "LMAT")
key_info$Site <- recode (key_info$Site, !!!Site_Names, .default = key_info$Site)
# check data
check_df <- subset(key_info,is.na(key_info$FileNum))
key_info$key <- paste0 (key_info$Site, "_",format(key_info$Date, format="%Y-%m-%d"), "_", key_info$FileNum)
key_info  <-  key_info %>%  mutate(key = paste0(format(Date, format="%Y-%m-%d"), "_", Site,
formatC(FileNum,width=5,flag="0")))
write.csv(key_info, paste0(format(key_info$Date,format ="%Y"),"_metadata_spectra.csv"))
write.csv(key_info, paste0(format(key_info$Date[1],format ="%Y"),"_metadata_spectra.csv"))
write.csv(key_info, paste0(format(key_info$Date[1],format ="%Y"),"_metadata_spectra.csv"))
# Read .spu data ---------------------------------------------------------
#  Process the .spu files in the chosen directory. The metadata from first 9 lines of the
#  the spu file will be read and a dataframe created.
data_path <- tk_choose.dir("./","****Choose a raw spu directory .")
spu_files <- list.files(path = data_path, pattern = ".spu$", full.names = T, recursive=T)
# Read all the metadata from the spu files using function read_spufile_metadata and add a variable with the file name
spu_data <- map_dfr(spu_files,read.spufile.metadata, .id="filename") %>%
mutate(filename=spu_files)
# Check for different spelling of site names
unique(spu_data$Site)
# Recode them to stadard ones.
Site_Names <- list(DH ="HTH", LHTH = "HTH", HIS="HIST", LOF = "LMAT", LSHB= "SHB", SHBB = "SHB", LWSG = "WSG", WSGB = "WSG" )
# Check for different spelling of site names
unique(spu_data$Site)
# Recode them to stadard ones.
Site_Names <- list(DH ="HTH", LHTH = "HTH", HIS="HIST", LOF = "LMAT", LSHB= "SHB", SHBB = "SHB", LWSG = "WSG", WSGB = "WSG" )
spu_data$Site <- recode (spu_data$Site, !!!Site_Names, .default = spu_data$Site)
# Check for different spelling of site names
unique(spu_data$Site)
write.csv(spu_data, paste0(data_path,"/",format(spu_data$DateTime[1], format="%Y"),"_spu_metadat.csv"))
# joint metadata to spu data.
unispec_data <- full_join(key_info,spu_data, by = "key")
write.csv(unispec_data, paste0("../",format(spu_data$DateTime[1], format="%Y"),"_unispecdata.csv"))
# Create a key variable that is unique for each spu file
spu_data <- spu_data %>%   mutate(key = paste0(format(DateTime, format="%Y-%m-%d"), "_", Site,
formatC(FileNum,width=5,flag="0")))
write.csv(spu_data, paste0(data_path,"/",format(spu_data$DateTime[1], format="%Y"),"_spu_metadat.csv"))
# joint metadata to spu data.
unispec_data <- full_join(key_info,spu_data, by = "key")
write.csv(unispec_data, paste0("../",format(spu_data$DateTime[1], format="%Y"),"_unispecdata.csv"))
read.spufile.metadata <- function(filename) {
#read metadata from first 9 lines and create a dataframe
text <- read_lines(filename, n_max=9)
# Extract metadata from filenames that have format "DATE/SITE_FILENUM.spu", e.g. "2018-06-22/DHT_00000.spu"
Site <- str_replace(filename,".*[/](.*)[_]+.*$","\\1") # get string after / & before _
# Extract metadata from filenames that have format "DATESITEFILENUM.spu", e.g. "JUN8LOF100036.spu"
if (str_length(Site) > 5)
{Site <- str_replace(filename,"(^.*?\\d{1,2})([a-zA-Z]*)(\\d{5,6}\\.spu$)","\\2")}
FileNum <- as.integer(str_extract(filename, "[0-9]{5,6}"))
# Extract unfo from the file itself
DateTime <-  lubridate::mdy_hms(text[3], tz="America/Anchorage")
Integration_ms <- as.numeric(strsplit(text[8], split = " ")[[1]][3])
Temp <- as.numeric(strsplit(strsplit(text[5], split = " ")[[1]][4], split="=")[[1]][2])
Remarks <- text[2]
Spufilename <- tolower(str_replace(text[1],".*[\\\\]([A-z0-9.]*).*$","\\1")) #Extract the file name in the file as a check
metaData <- data_frame(Site=Site, FileNum=FileNum, DateTime=DateTime, Integration_ms=Integration_ms,
Temp=Temp, Remarks=Remarks, Spufilename=Spufilename )
return(metaData)
}
# Read all the metadata from the spu files using function read_spufile_metadata and add a variable with the file name
spu_data <- map_dfr(spu_files,read.spufile.metadata, .id="filename") %>%
mutate(filename=spu_files)
# Check for different spelling of site names
unique(spu_data$Site)
# Recode them to stadard ones.
Site_Names <- list(DH ="HTH", LHTH = "HTH", HIS="HIST", LOF = "LMAT", LSHB= "SHB", SHBB = "SHB", LWSG = "WSG", WSGB = "WSG" )
spu_data$Site <- recode (spu_data$Site, !!!Site_Names, .default = spu_data$Site)
# Create a key variable that is unique for each spu file
spu_data <- spu_data %>%   mutate(key = paste0(format(DateTime, format="%Y-%m-%d"), "_", Site,
formatC(FileNum,width=5,flag="0")))
write.csv(spu_data, paste0(data_path,"/",format(spu_data$DateTime[1], format="%Y"),"_spu_metadat.csv"))
filename <- "JUL14 MAT00003.spu"
Site <- str_replace(filename,"(^.*?\\d{1,2})\\s([a-zA-Z]*)(\\d{5,6}\\.spu$)","\\2")
filename <- "JUL14MAT00003.spu"
Site <- str_replace(filename,"(^.*?\\d{1,2})\\s([a-zA-Z]*)(\\d{5,6}\\.spu$)","\\2")
Site <- str_replace(filename,"(^.*?\\d{1,2})\\s*([a-zA-Z]*)(\\d{5,6}\\.spu$)","\\2")
filename <- "JUL14 MAT00003.spu"
Site <- str_replace(filename,"(^.*?\\d{1,2})\\s*([a-zA-Z]*)(\\d{5,6}\\.spu$)","\\2")
read.spufile.metadata <- function(filename) {
#read metadata from first 9 lines and create a dataframe
text <- read_lines(filename, n_max=9)
# Extract metadata from filenames that have format "DATE/SITE_FILENUM.spu", e.g. "2018-06-22/DHT_00000.spu"
Site <- str_replace(filename,".*[/](.*)[_]+.*$","\\1") # get string after / & before _
# Extract metadata from filenames that have format "DATESITEFILENUM.spu", e.g. "JUN8LOF100036.spu"
if (str_length(Site) > 5)
{Site <- str_replace(filename,"(^.*?\\d{1,2})\\s*([a-zA-Z]*)(\\d{5,6}\\.spu$)","\\2")}
FileNum <- as.integer(str_extract(filename, "[0-9]{5,6}"))
# Extract unfo from the file itself
DateTime <-  lubridate::mdy_hms(text[3], tz="America/Anchorage")
Integration_ms <- as.numeric(strsplit(text[8], split = " ")[[1]][3])
Temp <- as.numeric(strsplit(strsplit(text[5], split = " ")[[1]][4], split="=")[[1]][2])
Remarks <- text[2]
Spufilename <- tolower(str_replace(text[1],".*[\\\\]([A-z0-9.]*).*$","\\1")) #Extract the file name in the file as a check
metaData <- data_frame(Site=Site, FileNum=FileNum, DateTime=DateTime, Integration_ms=Integration_ms,
Temp=Temp, Remarks=Remarks, Spufilename=Spufilename )
return(metaData)
}
# Read all the metadata from the spu files using function read_spufile_metadata and add a variable with the file name
spu_data <- map_dfr(spu_files,read.spufile.metadata, .id="filename") %>%
mutate(filename=spu_files)
# Check for different spelling of site names
unique(spu_data$Site)
# Recode them to stadard ones.
Site_Names <- list(DH ="HTH", LHTH = "HTH", HIS="HIST", LOF = "LMAT", LSHB= "SHB", SHBB = "SHB", LWSG = "WSG", WSGB = "WSG" )
spu_data$Site <- recode (spu_data$Site, !!!Site_Names, .default = spu_data$Site)
# Create a key variable that is unique for each spu file
spu_data <- spu_data %>%   mutate(key = paste0(format(DateTime, format="%Y-%m-%d"), "_", Site,
formatC(FileNum,width=5,flag="0")))
write.csv(spu_data, paste0(data_path,"/",format(spu_data$DateTime[1], format="%Y"),"_spu_metadat.csv"))
# joint metadata to spu data.
unispec_data <- full_join(key_info,spu_data, by = "key")
write.csv(unispec_data, paste0("../",format(spu_data$DateTime[1], format="%Y"),"_unispecdata.csv"))
filename <- "/JUL22WSG2200003.spu"
Site <- str_replace(filename,"(^.*?\\d{1,2})\\s*([a-zA-Z]*)(\\d{5,6}\\.spu$)","\\2")
filename <- "JUL22WSG2200003.spu"
Site <- str_replace(filename,"(^.*?\\d{1,2})\\s*([a-zA-Z]*)(\\d{5,6}\\.spu$)","\\2")
Site <- str_replace(filename,"(^.*?\\d{1,2})\\s*([a-zA-Z]*)(\\d{5,7}\\.spu$)","\\2")
read.spufile.metadata <- function(filename) {
#read metadata from first 9 lines and create a dataframe
text <- read_lines(filename, n_max=9)
# Extract metadata from filenames that have format "DATE/SITE_FILENUM.spu", e.g. "2018-06-22/DHT_00000.spu"
Site <- str_replace(filename,".*[/](.*)[_]+.*$","\\1") # get string after / & before _
# Extract metadata from filenames that have format "DATESITEFILENUM.spu", e.g. "JUN8LOF100036.spu"
if (str_length(Site) > 5)
{Site <- str_replace(filename,"(^.*?\\d{1,2})\\s*([a-zA-Z]*)(\\d{5,7}\\.spu$)","\\2")}
FileNum <- as.integer(str_extract(filename, "[0-9]{5,6}"))
# Extract unfo from the file itself
DateTime <-  lubridate::mdy_hms(text[3], tz="America/Anchorage")
Integration_ms <- as.numeric(strsplit(text[8], split = " ")[[1]][3])
Temp <- as.numeric(strsplit(strsplit(text[5], split = " ")[[1]][4], split="=")[[1]][2])
Remarks <- text[2]
Spufilename <- tolower(str_replace(text[1],".*[\\\\]([A-z0-9.]*).*$","\\1")) #Extract the file name in the file as a check
metaData <- data_frame(Site=Site, FileNum=FileNum, DateTime=DateTime, Integration_ms=Integration_ms,
Temp=Temp, Remarks=Remarks, Spufilename=Spufilename )
return(metaData)
}
# Read all the metadata from the spu files using function read_spufile_metadata and add a variable with the file name
spu_data <- map_dfr(spu_files,read.spufile.metadata, .id="filename") %>%
mutate(filename=spu_files)
# Check for different spelling of site names
unique(spu_data$Site)
# Recode them to stadard ones.
Site_Names <- list(DH ="HTH", LHTH = "HTH", HIS="HIST", LOF = "LMAT", LSHB= "SHB", SHBB = "SHB", LWSG = "WSG", WSGB = "WSG" )
spu_data$Site <- recode (spu_data$Site, !!!Site_Names, .default = spu_data$Site)
# Create a key variable that is unique for each spu file
spu_data <- spu_data %>%   mutate(key = paste0(format(DateTime, format="%Y-%m-%d"), "_", Site,
formatC(FileNum,width=5,flag="0")))
write.csv(spu_data, paste0(data_path,"/",format(spu_data$DateTime[1], format="%Y"),"_spu_metadat.csv"))
# joint metadata to spu data.
unispec_data <- full_join(key_info,spu_data, by = "key")
write.csv(unispec_data, paste0("../",format(spu_data$DateTime[1], format="%Y"),"_unispecdata.csv"))
read.spufile.metadata <- function(filename) {
#read metadata from first 9 lines and create a dataframe
text <- read_lines(filename, n_max=9)
# Extract metadata from filenames that have format "DATE/SITE_FILENUM.spu", e.g. "2018-06-22/DHT_00000.spu"
Site <- str_replace(filename,".*[/](.*)[_]+.*$","\\1") # get string after / & before _
# Extract metadata from filenames that have format "DATESITEFILENUM.spu", e.g. "JUN8LOF100036.spu"
if (str_length(Site) > 5)
{Site <- str_replace(filename,"(^.*?\\d{1,2})\\s*([a-zA-Z]*)(\\d{5,7}\\.spu$)","\\2")}
FileNum <- as.integer(str_extract(filename, "[0-9]{5,6}"))
# Extract unfo from the file itself
DateTime <-  lubridate::mdy_hms(text[3], tz="America/Anchorage")
Integration_ms <- as.numeric(strsplit(text[8], split = " ")[[1]][3])
Temp <- as.numeric(strsplit(strsplit(text[5], split = " ")[[1]][4], split="=")[[1]][2])
Remarks <- text[2]
Spufilename <- tolower(str_replace(text[1],".*[\\\\]([A-z0-9.]\\s*).*$","\\1")) #Extract the file name in the file as a check
metaData <- data_frame(Site=Site, FileNum=FileNum, DateTime=DateTime, Integration_ms=Integration_ms,
Temp=Temp, Remarks=Remarks, Spufilename=Spufilename )
return(metaData)
}
spu_data <- spu_data %>%   mutate(key = paste0(format(DateTime, format="%Y-%m-%d"), "_", Site, key_num))
# Create a key variable that is unique for each spu file
if (FileNum <6) {key_num = formatC(FileNum,width=,flag="0")}
# Create a key variable that is unique for each spu file
if (spu_data$FileNum <6) {key_num = formatC(spu_data$FileNum,width=,flag="0")}
spu_data <- spu_data %>%   mutate(if (FileNum <6) {key_num = formatC(FileNum,width=,flag="0")},
key = paste0(format(DateTime, format="%Y-%m-%d"), "_", Site, key_num))
spu_data <- spu_data %>%   mutate(if_else (FileNum <6, key_num = formatC(FileNum,width=,flag="0"), FileNum),
key = paste0(format(DateTime, format="%Y-%m-%d"), "_", Site, key_num))
spu_data <- spu_data %>%   mutate(if_else (FileNum <6, key_num = formatC(FileNum,width=5,flag="0"), FileNum),
key = paste0(format(DateTime, format="%Y-%m-%d"), "_", Site, key_num))
spu_data <- spu_data %>%   mutate(key_num = if_else (FileNum <6,  formatC(FileNum,width=5,flag="0"), FileNum),
key = paste0(format(DateTime, format="%Y-%m-%d"), "_", Site, key_num))
spu_data <- spu_data %>%   mutate(key_num = ifelse (FileNum <6,  formatC(FileNum,width=5,flag="0"), FileNum),
key = paste0(format(DateTime, format="%Y-%m-%d"), "_", Site, key_num))
View(spu_data)
spu_data <- spu_data %>%   mutate(key_num = ifelse (FileNum <999,  formatC(FileNum,width=5,flag="0"), FileNum),
key = paste0(format(DateTime, format="%Y-%m-%d"), "_", Site, key_num))
View(spu_data)
max(spu_data$FileNum)
max(key_info$FileNum)
key_info  <-  key_info %>%  mutate(key_num = ifelse (FileNum <999,  formatC(FileNum,width=5,flag="0"), FileNum),
key = paste0(format(DateTime, format="%Y-%m-%d"), "_", Site, key_num))
key_info  <-  key_info %>%  mutate(key_num = ifelse (FileNum <999,  formatC(FileNum,width=5,flag="0"), FileNum),
key = paste0(format(Date, format="%Y-%m-%d"), "_", Site, key_num))
max(key_info$FileNum)
# Read all the metadata from the spu files using function read_spufile_metadata and add a variable with the file name
spu_data <- map_dfr(spu_files,read.spufile.metadata, .id="filename") %>%
mutate(filename=spu_files)
key_info  <-  key_info %>%  mutate(key_num = ifelse (FileNum <999,  formatC(FileNum,width=5,flag="0"), FileNum),
key = paste0(format(Date, format="%Y-%m-%d"), "_", Site, key_num))
write.csv(key_info, paste0(format(key_info$Date[1],format ="%Y"),"_metadata_spectra.csv"))
spu_data <- spu_data %>%   mutate(key_num = ifelse (FileNum <999,  formatC(FileNum,width=5,flag="0"), FileNum),
key = paste0(format(DateTime, format="%Y-%m-%d"), "_", Site, key_num))
write.csv(spu_data, paste0(data_path,"/",format(spu_data$DateTime[1], format="%Y"),"_spu_metadat.csv"))
# joint metadata to spu data.
unispec_data <- full_join(key_info,spu_data, by = "key")
write.csv(unispec_data, paste0("../",format(spu_data$DateTime[1], format="%Y"),"_unispecdata.csv"))
