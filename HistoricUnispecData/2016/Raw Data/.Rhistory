nir <- c(820, 890)
red <- c(640, 680)
red_data <- tidydata %>%
filter(Wavelength >= red[1] & Wavelength <= red[2]) %>%
group_by(Site, Block, Treatment, Date, Measurement, Type) %>%
summarise(
red = mean(Reflectance)
)
nir_data <- tidydata %>%
filter(Wavelength >= nir[1] & Wavelength <= nir[2]) %>%
group_by(Site, Block, Treatment, Date, Measurement, Type) %>%
summarise(
nir = mean(Reflectance)
)
ndvi_data <- inner_join(nir_data, red_data) %>%
mutate(ndvi = (nir-red)/(red+nir))
return(ndvi_data)
}
# 1. Read in File Key --------------------------------------------------------
# This gives you the correspondence between each .spu file and the
# site / block / plot / treatment / measurement at which it was taken.
# Find all file keys
key_files <- list.files(path = data_path, pattern = "*_key.csv*", full.names = T, recursive = T)
# Read in filekeys
key_list <- data_frame(keyname = key_files) %>% # create dataframe
mutate(key_contents = map(keyname, function(x) read_key_file(x)))
keys <- unnest(key_list)
# 2. Multispec File Lists ----------------------------------------------------
# Create file lists (SITE-YEAR-MONTH-DAY-multispecstate.csv)
files <- list.files(path = data_path, pattern = "reflec|correct", full.names=T, recursive = T)
# 3. Read in data ---------------------------------------------------------
data_list <- data_frame(filename = files) %>% # create dataframe
mutate(file_contents = map(filename, function(x) read_multispec_file(x)))
data <- unnest(data_list)
## Join to File Key to get block, treatment, measurement
df <- inner_join(keys, data)
df_tidy <- df %>%
select(-c(filename, keyname)) %>%
filter(!(Treatment %in% c("REF", "DARK"))) %>% # Exclude the reference & dark
filter(Wavelength >=400 & Wavelength <= 1100) # Choose relevent wavelengths
data[Site=="X1"]
data
data %>% filter(Site=="X1")
data %>% filter(Site=="X2")
files
read_multispec_file(files[25])
## Read in multispec data files and plot
## AUTHOR: Ruby An
## DATE: 14 June 2018
# REQUIRED PACKAGES -------------------------------------------------------
require(tidyverse)
require(stringr)
require(lubridate)
# uses dplyr, tidyr, readr, ggplot2
# Directory -----------------------------------------------------------
data_path <- "/Users/toolik/Desktop/Multispec_All/"
#"/Users/toolik/Dropbox/Toolik-Summer-data/Toolik2017/Unispec/UnispecData"
# Functions ------------------------------------------
read_multispec_file <- function(multi_file) {
## Reads single multispec generated file
## Parses file name for usable info, format: SITE-{YEAR-MONTH-DAY}-TYPE.csv
## Reads in metadata from first 5 lines
## Reads in reflectance data (400-1100nm Wavelengths) from following lines
type <- str_extract(multi_file, "reflec|correct")
date <- ymd(str_extract(multi_file, "[\\d]{4}[-][\\d]+[-][\\d]+")) # regex for date
meta <- read_lines(multi_file, n_max=5, skip=0)
### Comma separated values:
## Line 1 - reference files (if corrected)
## Line 2 - list of .spu files.
## Line 3 - date # NOT ACCURATE
## Line 4 - time # NOT ACCURATE, multispec does something weird to times. In raw .spu files, they are accurate.
## Line 5 - temp / wind? # NOT USED
ref_files <- str_split(meta[1], pattern=",")[[1]]
spu_files <- str_split(meta[2], pattern=",")[[1]][-1] #Unlist & remove "Wavelength" to get list of data files
site <- str_extract(spu_files, "^(.*?)(?=_)") #str_split(spu_files, "_")[[1]][1]
fileNums <- as.numeric(str_extract(spu_files, "[\\d]{4,5}"))
#dates <- str_trim(str_split(meta[3], pattern=",")[[1]][-1])
#times <- str_split(meta[4], pattern=",")[[1]][-1]
## Parsing file name into variables, tag with type and date
site_fileNum_type_date <- str_c(site, fileNums, type, date, sep = "_")
## Read in what the file looks like, metadata in column name
multi_file_df <- read_csv(file = multi_file, skip = 6,
col_names = c("Wavelength", site_fileNum_type_date),
col_types = cols(
.default = col_double(),
Wavelength = col_integer()))
## Tidy up data frame
tidy_df <- multi_file_df %>%
gather(-Wavelength, key = "site_fileNum_type_date", value = "Reflectance") %>%
separate(site_fileNum_type_date, into = c("Site", "FileNum", "Type", "Date"), sep = "_", convert = T) %>%
mutate(Date = ymd(Date))
return(tidy_df)
}
read_key_file <- function(key_file) {
# Read in format of .csv
key_csv <- read_csv(file = key_file, col_names = T,
col_types = cols(
Site = col_character(),
Block = col_character(),
Treatment = col_character(),
Date = col_character(),
Measurement1 = col_integer(),
Measurement2 = col_integer(),
Measurement3 = col_integer(),
Measurement4 = col_integer(),
Measurement5 = col_integer()
))
# Consolidate measurements to tidy dataframe
key_df <- key_csv %>%
gather(Measurement, FileNum, Measurement1:Measurement5) %>%
filter(!is.na(FileNum)) %>%
mutate(Measurement = str_sub(Measurement, 12, 12)) %>%
mutate(Date = lubridate::mdy(Date))
return(key_df)
}
calculate_ndvi_multispec <- function(tidydata) {
nir <- c(820, 890)
red <- c(640, 680)
red_data <- tidydata %>%
filter(Wavelength >= red[1] & Wavelength <= red[2]) %>%
group_by(Site, Block, Treatment, Date, Measurement, Type) %>%
summarise(
red = mean(Reflectance)
)
nir_data <- tidydata %>%
filter(Wavelength >= nir[1] & Wavelength <= nir[2]) %>%
group_by(Site, Block, Treatment, Date, Measurement, Type) %>%
summarise(
nir = mean(Reflectance)
)
ndvi_data <- inner_join(nir_data, red_data) %>%
mutate(ndvi = (nir-red)/(red+nir))
return(ndvi_data)
}
# 1. Read in File Key --------------------------------------------------------
# This gives you the correspondence between each .spu file and the
# site / block / plot / treatment / measurement at which it was taken.
# Find all file keys
key_files <- list.files(path = data_path, pattern = "*_key.csv*", full.names = T, recursive = T)
# Read in filekeys
key_list <- data_frame(keyname = key_files) %>% # create dataframe
mutate(key_contents = map(keyname, function(x) read_key_file(x)))
keys <- unnest(key_list)
# 2. Multispec File Lists ----------------------------------------------------
# Create file lists (SITE-YEAR-MONTH-DAY-multispecstate.csv)
files <- list.files(path = data_path, pattern = "reflec|correct", full.names=T, recursive = T)
# 3. Read in data ---------------------------------------------------------
data_list <- data_frame(filename = files) %>% # create dataframe
mutate(file_contents = map(filename, function(x) read_multispec_file(x)))
data <- unnest(data_list)
## Join to File Key to get block, treatment, measurement
df <- inner_join(keys, data)
df_tidy <- df %>%
select(-c(filename, keyname)) %>%
filter(!(Treatment %in% c("REF", "DARK"))) %>% # Exclude the reference & dark
filter(Wavelength >=400 & Wavelength <= 1100) # Choose relevent wavelengths
data %>% filter(Site == "X3")
read_multispec_file(96)
read_multispec_file(files[96]
)
files
read_multispec_file(files[25])
read_multispec_file(files[26])
multi_file <- files[26]
type <- str_extract(multi_file, "reflec|correct")
date <- ymd(str_extract(multi_file, "[\\d]{4}[-][\\d]+[-][\\d]+")) # regex for date
meta <- read_lines(multi_file, n_max=5, skip=0)
ref_files <- str_split(meta[1], pattern=",")[[1]]
ref_files
read_multispec_file(files[26])
files
files[26]
read_multispec_file(files[26])
type <- str_extract(multi_file, "reflec|correct")
type
date <- ymd(str_extract(multi_file, "[\\d]{4}[-][\\d]+[-][\\d]+")) # regex for date
date
ref_files <- str_split(meta[1], pattern=",")[[1]]
meta
read_multispec_file(files[2])
read_multispec_file(files[25])
read_multispec_file(files[26])
read_multispec_file(files[26])
runApp('C:/Users/toolik/Desktop/shiny_multispec')
## Read in multispec data files and plot
## AUTHOR: Ruby An
## DATE: 14 June 2018
## Revised: 18 September 2018
## 10 Oct 2018 chaned to relative paths.  Jim Laundre
# REQUIRED PACKAGES -------------------------------------------------------
require(tidyverse)
require(stringr)
require(lubridate)
# uses dplyr, tidyr, readr, ggplot2
# Directory -----------------------------------------------------------
data_path <- "Toolik-Summer-data/Unispec/"
ls()
getwd
getwd()
# Create file lists (SITE-YEAR-MONTH-DAY-multispecstate.csv)
files <- list.files(path = data_path, pattern = "raw|correct", full.names=T, recursive = T)
choose.dir()
data-path <- choose.dir()
data_path <- choose.dir()
# Find all file keys
key_files <- list.files(path = data_path, pattern = "*_key.csv*", full.names = T, recursive = T)
# Read in filekeys
key_list <- data_frame(keyname = key_files) %>% # create dataframe
mutate(key_contents = map(keyname, function(x) read_key_file(x)))
keys <- unnest(key_list) # %>%
# Create file lists (SITE-YEAR-MONTH-DAY-multispecstate.csv)
files <- list.files(path = data_path, pattern = "raw|correct", full.names=T, recursive = T)
data_list <- data_frame(filename = files) %>% # create dataframe
mutate(file_contents = map(filename, function(x) read_multispec_file(x)))
View(data_list)
data <- unnest(data_list) #%>%
## Join to File Key to get block, treatment, measurement
keys_data <- inner_join(keys, data)
multispec_data_2017 <- keys_data %>%
select(-c(filename, keyname)) %>%
#filter(!(Treatment %in% c("REF", "DARK"))) %>% # Exclude the reference & dark
filter(Wavelength >=400 & Wavelength <= 1100) # Choose relevent wavelengths
save(multispec_data_2017, file = "Toolik-Summer-data/Unispec/multispec_data_2017a.Rda")
# Color sequences
pur_pal <- RColorBrewer::brewer.pal(5, "Purples")
####UNFISIHED
# SELECTION
sites <-c("SHB")
# Read in filekeys # create dataframe
key_list <- data_frame(keyname = key_files) %>%
mutate(key_contents = map(keyname, function(x) read_key_file(x)))
?filename
if (interactive())
choose.dir(getwd(), "Choose a suitable folder")
getwd()
?choose.dir
# QUALITY CHECK -----------------------------------------------------------
data_path <- "Toolik-Summer-data/Toolik2018/Unispec/UnispecData/Unispec4/"
## Read in select files // quality check ## REFERENCES
subfiles <- list.files(path = data_path, pattern = "*.spu", full.names = TRUE, recursive=T)
subdata_list <- data_frame(filename = subfiles) %>% # create dataframe
mutate(file_contents = map(filename, function(x) read_spu_file(x)))
install.packages(c("dplyr", "ps", "stringi"))
# QUALITY CHECK -----------------------------------------------------------
data_path <- "Toolik-Summer-data/Toolik2018/Unispec/UnispecData/Unispec4/"
## Read in select files // quality check ## REFERENCES
subfiles <- list.files(path = data_path, pattern = "*.spu", full.names = TRUE, recursive=T)
subdata_list <- data_frame(filename = subfiles) %>% # create dataframe
mutate(file_contents = map(filename, function(x) read_spu_file(x)))
install.packages("tidyverse")
# QUALITY CHECK -----------------------------------------------------------
data_path <- "Toolik-Summer-data/Toolik2018/Unispec/UnispecData/Unispec4/"
## Read in select files // quality check ## REFERENCES
subfiles <- list.files(path = data_path, pattern = "*.spu", full.names = TRUE, recursive=T)
subdata_list <- data_frame(filename = subfiles) %>% # create dataframe
mutate(file_contents = map(filename, function(x) read_spu_file(x)))
# REQUIRED PACKAGES -------------------------------------------------------
require(tidyverse)
require(stringr)
source('~/UnispecData/2018/read_spu_files.R', echo=TRUE)
# REQUIRED PACKAGES -------------------------------------------------------
require(tidyverse)
require(stringr)
require(lubridate)
# Directory -----------------------------------------------------------
data_path <- choose.dir()
read_multispec_file <- function(multi_file) {
## Reads single multispec generated file
## Parses file name for usable info, format: SITE_{YEAR-MONTH-DAY}_TYPE.csv
## Reads in metadata from first 5 lines
## Reads in reflectance data (400-1100nm Wavelengths) from following lines
type <- str_extract(multi_file, "raw|correct")
date <- ymd(str_extract(multi_file, "[\\d]{4}[-][\\d]+[-][\\d]+")) # regex for date
meta <- read_lines(multi_file, n_max=5, skip=0)
### Comma separated values:
## Line 1 - reference files (if corrected)
## Line 2 - list of .spu files.
## Line 3 - date # NOT ACCURATE
## Line 4 - time # NOT ACCURATE, multispec does something weird to times. In raw .spu files, they are accurate.
## Line 5 - temp / wind? # NOT USED
ref_files <- str_split(meta[1], pattern=",")[[1]]
spu_files <- str_split(meta[2], pattern=",")[[1]][-1] #Unlist & remove "Wavelength" to get list of data files
site <- str_extract(spu_files, "^(.*?)(?=_)") #str_split(spu_files, "_")[[1]][1]
fileNums <- as.numeric(str_extract(spu_files, "[\\d]{4,5}"))
#dates <- str_trim(str_split(meta[3], pattern=",")[[1]][-1])
#times <- str_split(meta[4], pattern=",")[[1]][-1]
## Parsing file name into variables, tag with type and date
site_fileNum_type_date <- str_c(site, fileNums, type, date, sep = "_")
## Read in what the file looks like, metadata in column name
multi_file_df <- read_csv(file = multi_file, skip = 6,
col_names = c("Wavelength", site_fileNum_type_date),
col_types = cols(
.default = col_double(),
Wavelength = col_integer()))
## Tidy up data frame
tidy_df <- multi_file_df %>%
gather(-Wavelength, key = "site_fileNum_type_date", value = "Reflectance") %>%
separate(site_fileNum_type_date, into = c("Site", "FileNum", "Type", "Date"), sep = "_", convert = T) %>%
mutate(Date = ymd(Date))
return(tidy_df)
}
read_key_file <- function(key_file) {
# Read in format of .csv
key_csv <- read_csv(file = key_file, col_names = T,
col_types = cols(
Site = col_character(),
Block = col_character(),
Treatment = col_character(),
Date = col_character(),
Measurement1 = col_integer(),
Measurement2 = col_integer(),
Measurement3 = col_integer(),
Measurement4 = col_integer(),
Measurement5 = col_integer()
))
# Consolidate measurements to tidy dataframe
key_df <- key_csv %>%
gather(Measurement, FileNum, Measurement1:Measurement5) %>%
filter(!is.na(FileNum)) %>%
mutate(Measurement = str_sub(Measurement, 12, 12)) %>%
mutate(Date = lubridate::mdy(Date))
return(key_df)
}
calculate_ndvi_multispec <- function(tidydata) {
nir <- c(820, 890)
red <- c(640, 680)
red_data <- tidydata %>%
filter(Wavelength >= red[1] & Wavelength <= red[2]) %>%
group_by(Site, Block, Treatment, Date, Measurement, Type) %>%
summarise(
red = mean(Reflectance)
)
nir_data <- tidydata %>%
filter(Wavelength >= nir[1] & Wavelength <= nir[2]) %>%
group_by(Site, Block, Treatment, Date, Measurement, Type) %>%
summarise(
nir = mean(Reflectance)
)
ndvi_data <- inner_join(nir_data, red_data) %>%
mutate(ndvi = (nir-red)/(red+nir))
return(ndvi_data)
}
# Useful vectors for filtering rows
WSG <- c("WSG1", "WSG23", "WSG")
SHB <- c("SHB1", "SHB2", "SHB")
site_list <- list("MAT", "LMAT", "MNAT", "NANT", "DHT", WSG, SHB, "HST")
CT <- c("CT","CT1","CT2")
NP <- c("F0.5","F1","F2","F5","F10","NP", "NO3", "NH4")
trtmt_list <- list(CT, "N", "P", NP)
# Find all file keys
key_files <- list.files(path = data_path, pattern = "*_key.csv*", full.names = T, recursive = T)
# Read in filekeys
key_list <- data_frame(keyname = key_files) %>% # create dataframe
mutate(key_contents = map(keyname, function(x) read_key_file(x)))
keys <- unnest(key_list) %>%
mutate(Site = replace(Site, Site %in% WSG, "WSG")) %>%
mutate(Site = replace(Site, Site %in% SHB, "SHB"))
# Create file lists (SITE-YEAR-MONTH-DAY-multispecstate.csv)
files <- list.files(path = data_path, pattern = "raw|correct", full.names=T, recursive = T)
data_list <- data_frame(filename = files) %>% # create dataframe
mutate(file_contents = map(filename, function(x) read_multispec_file(x)))
data <- unnest(data_list) %>%
mutate(Site = replace(Site, Site %in% WSG, "WSG")) %>%
mutate(Site = replace(Site, Site %in% SHB, "SHB"))
## Join to File Key to get block, treatment, measurement
keys_data <- inner_join(keys, data)
getwd()
setwd("~/UnispecData/2018/UnispecData")
dir_name <- list.dirs('.', recursive=FALSE)
setwd("~/UnispecData/2016/Raw Data")
dir_name <- list.dirs('.', recursive=FALSE)
test <- "12JUL2016_HIST_ALL"
this.dir <- dirname(parent.frame(2)$ofile)
rstudioapi::getActiveDocumentContext
dirname(rstudioapi::getActiveDocumentContext()$path)
# Create file lists (SITE-YEAR-MONTH-DAY-multispecstate.csv)
files <- list.files(path = data_path, pattern = "raw|correct", full.names=T, recursive = T)
# Create file lists (SITE-YEAR-MONTH-DAY-multispecstate.csv)
files <- list.files(path = data_path, pattern = "2016", full.names=T, recursive = T)
files
# Create file lists (SITE-YEAR-MONTH-DAY-multispecstate.csv)
files <- list.files(path = ., pattern = "2016", full.names=T, recursive = T)
# Create file lists (SITE-YEAR-MONTH-DAY-multispecstate.csv)
files <- list.files("", pattern = "2016", full.names=T, recursive = T)
?list.files
# Create file lists (SITE-YEAR-MONTH-DAY-multispecstate.csv)
files <- list.files(".", pattern = "2016", full.names=T, recursive = T)
files
# Create file lists (SITE-YEAR-MONTH-DAY-multispecstate.csv)
files <- list.files(".", pattern = "2016", full.names=T, recursive = f)
# Create file lists (SITE-YEAR-MONTH-DAY-multispecstate.csv)
files <- list.files(".", pattern = "2016", full.names=T, recursive = F)
?mutate
View(keys)
pattern = "(2016)"
replacement = "\\1^"
sub(pattern,replacement,test)
grep("+_",test,value=T)
sub("(^.)+_","\\1",test, value=T)
sub("(^.)+_","\\1",test)
sub("(^[[:anum:]])+_","\\1",test)
sub("(^[[:alnum:]])+_","\\1",test)
sub("(^[[:alnum:]])","\\1",test)
sub("(^[[:alpha]])","\\1",test)
sub("(^[[:alpha:]])","\\1",test)
sub("([[:alpha:]])","\\1",test)
sub("(_)","\\1",test)
sub("(_)","\\s",test)
sub("(_)","[[:space:]]",test)
sub("(_)",[[:space:]],test)
sub("(_)"," ",test)
grep("[A-z)-9]\\>",test,value=T)
?rownames
?names()
# print the names attribute of the islands data set
names(islands)
# remove the names attribute
names(islands) <- NULL
islands
rm(islands) # remove the copy made
z <- list(a = 1, b = "c", c = 1:3)
names(z)
# change just the name of the third element.
names(z)[3] <- "c2"
z
z <- 1:3
names(z)
## assign just one name
names(z)[2] <- "b"
z
states = rownames(USArrests)
states2 = abbreviate(states)
states2
head(states2)
names(states2)=NULL
states2
sub("(\\w+)_(\\w+)",//1,test)
sub("(\\w+)_(\\w+)",\\1,test)
sub("(\\w+)_(\\w+)","\\1",test)
sub("^(\\w+)_(\\w+)","\\1",test)
sub("^(\\w+)_{1}(\\w+)","\\1",test)
sub("^(\\w+)_{2}(\\w+)","\\1",test)
sub("^(\\w+)_?(\\w+)","\\1",test)
sub("^(\\w*)_(\\w+)","\\1",test)
sub("^(\\w?)_(\\w+)","\\1",test)
sub("^(\\w{1})_(\\w+)","\\1",test)
sub("^(\\w)_(\\w+)","\\1",test)
sub("(\\w)_(\\w+)","\\1",test)
sub("(\\w)_(\\w+)","\\2",test)
sub("(\\w)_(\\w)","\\2",test)
str_replace(test,pattern="(\\w)_(\\w)","\\1")
str_replace(test,pattern="(\\w)_","\\1")
str_replace(test,pattern="(\\w)_(+)","\\2\\1")
str_replace(test,pattern="(\\w)_(.+)","\\2\\1")
str_split(test,pattern="_")
tep_name <-str_split(test,pattern="_")
tep_name[1]
tep_name = str_split(test,pattern="_")
tep_name
tep_name[2]
typeof(tep_number)
typeof(tep_name)
tep_name2 <-str_split(test,pattern="_")
tep_name[[2]]
tep_name[[1]]
tep_name[[1]][1]
strptime(tep_name[[1]][1],format=%d%b%y,%y-%m-%d)
strptime(tep_name[[1]][1],"%d%b%y",%y-%m-%d)
strptime(tep_name[[1]][1],"%d%b%y","%y-%m-%d"")
""
strptime(tep_name[[1]][1],"%d%b%y","%y-%m-%d")
strptime(tep_name[[1]][1],"%d%b%y")
strptime(tep_name[[1]][1],format = "%d%b%y","%y")
strptime(tep_name[[1]][1],format = "%d%b%y","tz="")
;
""
strptime(tep_name[[1]][1],format = "%d%b%y","tz=")
strptime(tep_name[[1]][1],format = "%d%b%y","")
View(tep_name)
as.Date(tep_name[[1]][1])
as.Date(tep_name[[1]][1],%d%b%y)
as.Date(tep_name[[1]][1],"%d%b%y")
as.Date(tep_name[[1]][1],"%d%b%Y")
str_split(test,"_")
str_extracr(test,"_")
str_extract(test,"_")
str_extract(test,"\\d+_")
str_extract(test,"^\\d+_")
str_extract(test,"^(\\d+)_")
str_extract(test,"(\\d+)_")
str_extract(test,"(\\w+)_")
str_extract(test,"^(\\w+)_")
str_extract(test,"^(.)_")
str_extract(test,"^([A-z0-9])_")
str_extract(test,"([A-z0-9])_")
str_extract(test,"[^_]+")
setwd("~/UnispecData/2018/UnispecData")
files <- list.files(".", pattern = "2016", full.names=T, recursive = F)
dir_name <- list.dirs('.', recursive=FALSE)
setwd("~/UnispecData/2016/Raw Data")
files <- list.files(".", pattern = "2016", full.names=T, recursive = F)
dir_name <- list.dirs('.', recursive=FALSE)
str_extract(dir_name,"[^_]+")
str_extract(dir_name,"[^\\./_]+")
dir_date <-str_extract(dir_name,"[^\\./_]+")
as.date(dir_date,"%d%b%y")
as.Date(dir_date,"%d%b%y")
as.Date(str_extract(dir_name,"[^\\./_]+"),"%d%b%Y")
str_extract(files,"_.*")
new_dir_name <- paste(as.Date(str_extract(dir_name,"[^\\./_]+"),"%d%b%Y"),str_extract(files,"_.*"))
?paste()
new_dir_name <- paste0(as.Date(str_extract(dir_name,"[^\\./_]+"),"%d%b%Y"),str_extract(files,"_.*"))
