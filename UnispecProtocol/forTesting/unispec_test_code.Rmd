---
title: "Process Unispec Files collected on One Day"
author: "Ruby An"
date: "2021-07-29"
output: html_document
params: 
  data_path: C:\Users\TerrestrialRA\Desktop\rawUnispec\2021-06-14
  #select folder where .spu files are. No string quotes for data_path ("")
---

## Introduction
This file is for processing unispec data in a user friendly way. 

## Required Packages & Functions
```{r setup, include=FALSE}
rm = list(ls())
knitr::opts_chunk$set(echo = F, message=F)

## Required Packages

library(knitr)
library(rChoiceDialogs)
library(lubridate)
library(purrr)
library(tidyverse)

## R FUNCTIONS for processing spu data
read_spu_file_metadata <- function(filename, info = "short") {
  # DESCRIPTION: Reads first 9 text lines in .spu files 
  # INPUT: .spu file -- collected using PPSystems UnispecDC
  #         info = "short", the default returns only the spu_filename, DateTime, FileNum, Integration time
  #                "long", returns all the info in the 9 lines of header in .spu files
  # OUTPUT: dataframe with 15 columns on instrument status, scan settings, max/min value

    # Extract info from the file itself, reading metadata from first 9 lines. Create a dataframe
    text <- read_lines(filename, n_max=9)
    
    # Line 1: Extract the file name in the spu file as a check. Some file names have spaces 
    spu_filename <- str_replace(text[1],".*[\\\\]([A-z0-9.]\\s*)","\\1") %>% # extract filename
      str_replace("\"","") # removes trailing quote at end of line 
    FileNum <- str_extract(spu_filename, "\\d{5}") %>% as.numeric() # from 5 digits in filename
    
    # Line 2: 
    Remarks <- str_split(text[2], pattern = " ")[[1]] # split by "space"
    Type <- str_split(Remarks[7], pattern = "=")[[1]][2] # extract relevant part
    ScanType <- ifelse(grepl("DARKscan",Type, fixed=T), "DARKscan", # format
                       ifelse(grepl("Datascan,DC",Type, fixed=T), "Throwawayscan", 
                              Type))
    DarkscanID <- str_extract(text[2], "Dark=.+.spu")
    Remarks <- text[2]
    
    # Line 3: 
    DateTime <-  lubridate::mdy_hms(text[3], tz="America/Anchorage")
    
    # Line 4: Limits -- range of spectra measured
    Limits <- str_extract(text[4], "\\d+.\\d.+\\d") 
    
    # Line 5: 
    Temperature <- as.numeric(strsplit(strsplit(text[5], split = " ")[[1]][4], split="=")[[1]][2])
    Battery <- str_extract(text[5], "BattV=\\d+.\\d+")
    Aux <- str_extract(text[5], "A\\d=.+\\d")
    
    # Line 6-9: 
    Minimum <- str_extract(text[6], "\\d+.+\\d") # Wavelength, ChB min
    Minimum_wavelength <- str_split(Minimum, boundary("word"))[[1]][1] # Wavelength
    Minimum_value <- str_split(Minimum, boundary("word"))[[1]][2] # ChB AD
    
    Maximum <- str_extract(text[7], "\\d+.+\\d") # Wavelength, ChB max
    Maximum_wavelength <- str_split(Maximum, boundary("word"))[[1]][1]
    Maximum_value <- str_split(Maximum, boundary("word"))[[1]][2]

    Integration <- as.numeric(strsplit(text[8], split = " ")[[1]][3])
    NumberScans <- str_extract(text[9], "\\d+")
    
    # Truncated Filename - use as SCANID to join to other dataframes
    spu_filename <- unlist(str_split(filename, pattern = "/")) %>% last()
    
    # Metadata 
    metadata <- tibble(spu_filename, DateTime, FileNum, ScanType, Integration, NumberScans,Minimum_wavelength,Minimum_value, Maximum_wavelength, Maximum_value, Limits, Temperature, Battery, Aux, DarkscanID, Remarks)
    
    if(info == "short") {
      metadata <- metadata %>% select(spu_filename, DateTime, FileNum, Integration)
    }

  # Print filenames while reading 
  #print(spu_filename) # use for error checking
  
  return(metadata)
}


read_spu_file_spectra <- function(filename) {
  # DESCRIPTION: For a generic .spu file regardless of name, extract spectral data
  # INPUT: Unispec-DC .spu file
  # OUTPUT: dataframe of spectral data with 3 columns Wavelength, ChB, ChA
  
  # Read spectral intensity data into dataframe
  data <- read.table(file = filename, skip = 9, col.names = c("Wavelength", "ChB", "ChA"))
  
  print(filename)
  
  return(data)
}


# Assign nearest reference value
assign_closest_ref <- function(data_int, ref_int) {
  # Get the nearest integration 
  
  pick <- which(abs(ref_int-data_int) == min(abs(ref_int-data_int)))
  
  REF_Integration <- ref_int[pick]
  
  return(REF_Integration)
}

# Color band definitios for calculate_indices function
band_defns <- tribble(
  ~definition, ~color, ~min, ~max,
  "ITEX", "red", 560, 600,
  "ITEX", "nir", 725, 1000,
  "MODIS", "red", 620, 670, 
  "MODIS", "nir", 841, 876,
  "MODIS", "blue", 459,479,
  "SKYE", "red", 620, 680,
  "SKYE", "nir", 830, 880,
  "SKYE", "blue", 455, 480,
  "ToolikGIS_Drone_2018", "red", 640, 680,
  "ToolikGIS_Drone_2018", "nir", 820, 890,
  "ToolikGIS_MicaSense_2019", "blue", 455, 495,
  "ToolikGIS_MicaSense_2019", "green", 540, 580,
  "ToolikGIS_MicaSense_2019", "red", 658, 678,
  "ToolikGIS_MicaSense_2019", "red_edge", 707, 727,
  "ToolikGIS_MicaSense_2019", "near_ir", 800, 880,
  "ToolikEDC", "red", 560, 680,
  "ToolikEDC", "nir", 725, 1000
)

calculate_indices <- function(spectra, band_defns, instrument = "MODIS", indices = "NDVI") {
  # Calculates NDVI, EVI, and EVI2 from dataframe including Wavelength : Spectra 
  ## inputs: spectra - dataframe with Wavelength, Reflectance columns
  ##         band_defns : dataframe defining wavelengths definining colors 
  ##         instrument : e.g. MODIS, SKYE, ITEX
  ##         indicies   : the index to return 
  ## output: Index - name of vegetation index
  ##         BandDefinition - name of "instrument" or spectral band definition used
  ##         Value - value of index, with the band definition used. 
  
  bands <- band_defns %>% 
    filter(definition == instrument) 
  
  blue <- bands %>% filter(color=="blue") %>% select(min, max) %>% as.numeric()
  nir <- bands %>% filter(color=="nir") %>% select(min, max) %>% as.numeric()
  red <- bands %>% filter(color=="red") %>% select(min, max) %>% as.numeric()
  
  spectra_bands <- spectra %>% 
    mutate(color = ifelse(Wavelength >= blue[1] & Wavelength <= blue[2], "blue",
                          ifelse(Wavelength >= red[1] & Wavelength <= red[2], "red",
                                 ifelse(Wavelength >= nir[1] & Wavelength <= nir[2], "nir",
                                        "other")))) %>% 
    group_by(color) %>% 
    summarize(Reflectance = mean(Reflectance))
  
  index_data <- spectra_bands %>%
    spread(color, Reflectance) %>% 
    
    ## INDEX DEFINITIONS
    mutate(NDVI = (nir-red)/(nir+red),
           EVI = 2.5*((nir-red)/(nir+6*red-7.5*blue + 1)),
           EVI2 = 2.5*((nir-red)/(nir+2.4*red + 1))) %>% 
    select_at(indices) %>% 
    gather(Index, Value, everything()) %>% 
    
    # Add Spectral Band Definition convention
    mutate(BandDefinition = instrument) %>% 
    select(Index, BandDefinition, Value)
  
  return(index_data) 
}


## SANITY CHECK FUNCTIONS

check_scan_times <- function(raw_data) {
  
  timedata <- raw_data %>% 
    select(Site, DateTime, FileNum) %>% 
    distinct(DateTime, .keep_all = T)
  
  # Calculate time between scans 
  timedata$diff <- timedata$DateTime - lag(timedata$DateTime)
  
  meta_timedata <- left_join(timedata, field_keys)
  
  time_check <- meta_timedata %>% select(Site, DateTime, Block, Treatment, Replicate, FileNum, diff, everything()) %>% ungroup()
  
  return(time_check)
}

```

## Read in data
  
  * data_path is year folder where the session files are stored. The structure is year/spu/yyyy-mm-dd  where yyyy-mm-dd is sample date. Should be on OneDrive.
  
  * Field Key file with header "Date,Site,Block,Treatment,Replicate,Location,FileNum,Notes,Weather".  File name convention is year_unispec_field_key.csv

### Read .SPU files 
  
```{r, include = F}
## INPUTS:
# - path to data folder containing .spu files
# - param: set in header

# Manually choose folder with .spu files
if(interactive()){
  data_path <- rchoose.dir(caption = "Select directory containing .spu files")
} else 
  {data_path <- params$data_path}

## Make a character vector of all .spu raw files in current session date folder
# Check if directory exist and use it as the working directory

spu_files <- list.files(path = data_path, pattern = ".spu$", full.names = T, recursive=T)

# Read metadata text lines (9) from the spu files
spu_filedata <- map_dfr(spu_files, read_spu_file_metadata)

## Add Metadata columns:
#   spu_filename_full: variable with the full path filename 
#   Site: column from spu_filename
#   FileNum: column from spu_filename 
#   ScanType: column identifying scan type (Dark, Throwaway, Datascan)

spu_metadata <- spu_filedata %>% 
  mutate(spu_filename_full = spu_files) %>% #
  mutate(Site = toupper(str_extract(spu_filename, "[A-Za-z]{3}[0-9]{1,2}(?=_)"))) %>%
  # get string that is 3 letters, 2 numbers before _ 
  
  mutate(FileNum = as.integer(str_extract(spu_filename, "\\d{5}"))) 

# Read spectra from .spu files > add to metadata
spu_dataframe <- spu_metadata %>% 
  mutate(Spectra=map(spu_filename_full, function(x) read_spu_file_spectra(x))) %>% 
  mutate(Date = date(DateTime))

```

### Read Unispec File Key
```{r}
## INPUTS:
# - *unispec_key.csv file
# - spu_dataframe of spu files with corresponding site, date, and file numbers to the key

# Manually choose key files 
#key_files <- rchoose.files(caption = "Choose Unispec File Key", multi = T)

# Choose key files
key_files <- list.files(path = data_path, pattern = "*template.csv$", full.names = T, recursive=T)

field_keys <- key_files %>% purrr::map(function(file_name) read_csv(file_name,
                                                                    col_select = c(1:7))) %>%
  reduce(rbind) %>%
  mutate(Date = lubridate::parse_date_time(Date, c("mdy", "ymd")))

# Join by SITE, DATE, FILENUM
raw_data <- left_join(field_keys, spu_dataframe) %>% arrange(DateTime) %>% 
  mutate_at(.vars = vars(Site, Block, Treatment), .funs = factor)
```


### QAQC: Unispec Key & .spu file Correspondance  

```{r missing, warnings=F}
# This chunk prints a bunch of checks at the end. Read through it to check that nothing is amiss. 

## Data summary
spu_dataframe %>%
  mutate(Date = floor_date(DateTime, unit="day")) %>% 
  group_by(Date, Site) %>% 
  summarize(Files = n_distinct(spu_filename)) %>% 
  kable(caption = "Raw .spu files read-into spu_dataframe")

## Print Summary of files 
raw_data %>% group_by(Date, Site, Block) %>%  
  filter(!is.na(Treatment)) %>% 
  summarize(Treatments = str_c(str_replace_na(sort(unique(Treatment))), collapse = ","), Num_Files = n()) %>% 
  kable(caption ="Files listed in field key")

### MISSING: Identify any measurement locations that are missing corresponding raw spu files. By checking the overlap between "field_keys" and "spu_dataframe", this code lists (a) missing raw .spu files OR (b) extra .spu files that aren't accounted for in the unispec field keys. 

## Identify any missing files (or extra files)
missing_spu_files <- anti_join(field_keys, spu_dataframe)

## Is anything missing from the field keys? 
#### Look for NA's indicating missing info
missing_info <- raw_data %>% 
  filter(is.na(spu_filename) | # spu_filename
         is.na(Site) | # site
         is.na(Block) & !str_detect(Treatment, "REF|DARK|VEG") | # Block NA's should always be REFS or EXTRA
         is.na(Replicate) & !str_detect(Treatment, "REF|DARK|THROWAWAY"), # Check for replicate NA's that aren't REF
         Treatment != "EXTRA|VEG|REF") %>% # don't care about EXTRA, VEG, or REF scans
  select(spu_filename, FileNum, Site, Block, Treatment, Replicate, everything()) # reorder columns to see output better

### Identify any files that aren't listed in the field key
extra_files <- anti_join(spu_dataframe, field_keys) %>% pull(spu_filename)


### MISLABELING: Check for human error in recording location correspondence between metadata and .spu file numbers. 

## Check File Number Pattern -- The number of files per block should be multiples of 5, unless REF or NA. This code identifies any plots that are not multiples of 5.
df_filenum_count <- field_keys %>% group_by(Site, Date, Block, Treatment) %>% 
    summarize(Num_Files = n()) %>% # count the number of files
    filter(Num_Files %% 5 != 0) %>%   # files per plot
    
    # Remove scans that aren't of plot locations (DARK, REF, THROWAY)
    filter(Treatment != "THROWAWAY") %>% # filter out scantypes that don't correspond to plot measurement locations
    filter(Treatment != "DARK") %>% 
    filter(! "REF" %in% Treatment) 


# Print output 
## Confirm the number of spu files 
print(paste0("Total number of .spu files: ", nrow(spu_dataframe)))
print(paste0("Total number of scans documented: ", nrow(field_keys)))
## Missing things
print("QUALITY CHECKS: all answers should be zero if things ran well")
print(paste0("Missing .spu files: ", nrow(missing_spu_files)))
print(paste0("Scan Locations missing info: ", nrow(missing_info)))
## Mislabeling
print(paste0("Plots with an abnormal number of scans (not a clean multiple of 5): ", nrow(df_filenum_count)))


```

### QAQC: Instrument Check



#### Max'd Out Spectra (> 65000 AD)
List files that maxed out, in the wavelengths used to calculate MODIS NDVI.
```{r maxed, dependson="raw_data"}

maxed_data <- raw_data %>% inner_join(spu_dataframe %>% select(spu_filename)) %>% # restrict to those w/.spu files
  unnest(Spectra) %>% 
  filter(ChA > 65000 | ChB > 65000) %>% 
  group_by(spu_filename) %>% 
  summarize(maxed_number = n(), maxed_wavelengths = str_c(min(Wavelength), " - ", max(Wavelength), collapse = ", "))  

# Print MAXED files 
if (nrow(maxed_data) > 0) {
  raw_data %>% select(spu_filename, Site, Date, Block, Treatment, Replicate) %>% 
     inner_join(maxed_data)
  
  # Maxed file list 
  maxed_files <- maxed_data$spu_filename
  
} else { print("no maxed files")}


```


#### Dim'd Out Spectra
Primarily Darkscans should show up. 

```{r dim, dependson=raw_data, warnings=F}
dim_data <- raw_data %>%  
  unnest(Spectra) %>% 
  group_by(spu_filename) %>% 
  summarize(ChA_max = max(ChA)) %>% 
  filter(ChA_max < 20000) %>% 
  left_join(raw_data)

# Print DIM files  
if (nrow(dim_data) > 0) {
  dim_data %>% select(spu_filename, Site, Date, Block, Treatment, Replicate, ChA_max) %>% 
    kable()
  
  # File List
  dim_files <- dim_data$spu_filename
  
} else { print("no dim files")}


```


#### Zero'd Spectra
```{r zerod, dependson="raw_data"}
## zero'd data 
zero_data <- raw_data %>% unnest(Spectra) %>% 
  filter(ChA == 0) %>%  ## This is for all wavelengths, not just 400-1000nm
    filter(Wavelength > 400, Wavelength < 1000)  %>% 
  group_by(spu_filename) %>% 
  summarize(Zeros = n())

# Print ZEROD files 
if (nrow(zero_data) > 0) {
  ## File List : Restricted Wavelengths
  (zero_files <- zero_data %>% left_join(spu_dataframe) %>% unnest(Spectra) %>% 
    filter(ChA == 0 ) %>% 
    pull(spu_filename) %>% unique() %>%
    select(spu_filename, Site, Date, Block, Treatment, Replicate, Zeros))
  
} else 
  {print("no zero'd files")}
  
```


## Correct data with REFerence files

White references correct for instrument & cable irregularities. Multiplying by the correction factor (ChA/ChB) smooths out the spectra. There are typically 5 reference measurements per *Date* / *Site*. If multiple file numbers are listed, the correction factors are averaged. 

Based on the original field notebook key and the following quality checks, choose reference files by entering the appropriate file numbers in the field keys for the rows where the column *Treatment* = **REF**. 

Make sure to rerun the **Read Unispec Keys** if you change REF file choices. The following code plots your chosen references for a visual check.

### Choose & Check References
```{r ref_choice_list}
## INPUTS:
# - raw_data, including the reference files


# Create a vector of reference files (either by treatment labels, as below or some other method)
ref_files <- raw_data %>% 
  filter(Treatment == "REF") %>% 
  select(spu_filename) %>% pull()

ref_data <- raw_data %>% 
  
  ## Get the spectra for reference files
  filter(spu_filename %in% ref_files) %>% 
  
  ### Unnest Spectra & calculate correction factor
  unnest(Spectra) %>% 
  filter(Wavelength > 400, Wavelength < 1000) %>% # remove edge wavelengths, instrument unreliable at extremes
  
  mutate(correction_factor = ChA/ChB) %>% 

  ### Group repeated REF measurements based on your plot set-up (choose Block or NOT)
  group_by(Date,Site,Integration,Wavelength)


## Calculate correction factors by averaging 5 chosen ref measurements per DATE/SITE & calculate mean correction factors
correction_factors <- ref_data %>% 
  summarize(correction_factor = mean(ChA/ChB), 
            ref_filenames = str_c(spu_filename,collapse = ", ")) 

## QUALITY CHECK
## Table per Site of Reference Files 
(ref_filenames_table <- ref_data %>% group_by(Date, Site, Integration) %>% 
  summarize(Files = n_distinct(spu_filename), ref_filenames = str_c(spu_filename,collapse = ", ")) )

## Build Plot all reference data files
mean_refs <- correction_factors %>% 
  rename(spu_filename = ref_filenames) %>% 
  mutate(average = "average")
single_refs <- ref_data %>% 
  mutate(average = "single")

### VIZ
(ref_plot <- ggplot(full_join(mean_refs, single_refs),
                    aes(x = Wavelength, 
                        y = correction_factor)) + 
  theme(legend.position="left") + 
  geom_line(aes(color=factor(Integration), linetype = factor(average))) + 
  
  # Formatting
  labs(title = "White Reference Correction Factors",
       subtitle = "Visually check to make sure references look OK.",
       x = "Wavelength (nm)", 
       y = "Correction Factor") + 
  scale_linetype_discrete(name = "Files") + 
  scale_color_discrete(name = "Integration time (ms)") + 
  theme_light()
  
  ) 

```

### Apply References
Rerun the **Join Data & keys** sections above to update the `raw_data` dataframe. Apply your chosen references to actual spectral data to create the tidy dataframe `processed_data` containing corrected sepectral reflectance values.

INPUTS:
- raw_data
- correction_factors

OUTPUT:
- processed_data
- plot of first 30 files to check

```{r apply_refs, echo=FALSE}

#------ 
# Get integration times of ref data
ref_int_values <- unique(correction_factors$Integration)


## Join DATA with REFS

raw_data_with_refs <- raw_data %>% 
  
  # unlist Spectra and remove edge wavelengths, because instrument unreliable at extreme wavelengths
  unnest(Spectra) %>% 
  filter(Wavelength > 400, Wavelength < 1000) %>%
  
  # assign the "REF_Integration" value closest to data scan integration time
  rowwise() %>% 
  mutate(REF_Integration = assign_closest_ref(Integration, ref_int_values)) %>% 
  ungroup() %>% 

  # join data with ref data
  left_join(correction_factors %>% rename(REF_Integration = Integration)) %>%
  select(-REF_Integration) %>%  # drop joining column, no longer needed
  
  # calculate reflectances
  mutate(raw_reflectance = ChB/ChA) %>% # the raw reflectance
  mutate(corrected_reflectance = raw_reflectance*correction_factor) # corrected reflectance


## Corrected Reflectances with one row per file
processed_data <- raw_data_with_refs %>% 
  nest(processed_spectra = c(Wavelength, ChB, ChA, correction_factor, raw_reflectance, corrected_reflectance))
```

### QAQC application
```{r}

## Check all files have a corrected reflectance

missing_corrections <- processed_data %>%  filter(processed_spectra %>% map(is.null) %>% map_lgl(any)) # remove files w/out spu_spectra

corrected_spectra_files <- processed_data %>% 
  unnest(processed_spectra) %>% 
  filter(!is.na(corrected_reflectance)) %>% # check the column is calculated
  select(spu_filename, Date, Site) %>% distinct()


print(paste0("Number of raw files: ", nrow(raw_data)))
print(paste0("Number of corrected Files: ", nrow(corrected_spectra_files)))

## print treatments missing corrections
if(nrow(processed_data) != nrow(raw_data)) {
  anti_join(raw_data, corrected_spectra_files) %>% 
  group_by(Date, Site, Block, Treatment, Integration) %>% 
  summarize(Num_Files = n()) %>% kable()
  
  anti_join(raw_data, processed_data, by = "spu_filename") %>% pull(Treatment) %>% unique() %>% print()
  
  print(missing_corrections)
}

##### VIZ: Plot Check first 30 files

(processed_data %>% 
    slice(1:30) %>% 
    # make consolidated location label so it's more readable
  mutate(Location = str_c(Site, "-", Block, "-", Treatment)) %>% 
    #reformat data to plot

  unnest(processed_spectra) %>% 
  gather(key = Status, value = Reflectance, raw_reflectance, corrected_reflectance) %>% 
  
  # VIZ
  ggplot(mapping = aes(x = Wavelength, y = Reflectance )) + 
  geom_line(aes(color = spu_filename, linetype = Status)) + 
    facet_wrap(vars(Date, Location)) + 
  theme_light())

```


## Calculate INDICES

Currently, this only works for NDVI, EVI, and EVI2 as I haven't worked out spectral interpolation yet and the other indices need reflectance at a specific value (not a range).


### Calculate Indices
```{r}

index_data <- processed_data %>% 
  
  ## Format for calculuating indices function
  unnest(processed_spectra) %>%
  select(-ChB, -ChA, -raw_reflectance, -correction_factor) %>%
  rename(Reflectance = corrected_reflectance) %>%
  nest(Spectra = c(Wavelength, Reflectance)) %>%
  
  
  ## Calculate NDVI
  mutate(Indices = map(Spectra, function(x) calculate_indices(x, band_defns = band_defns, instrument = "MODIS", indices = c("NDVI", "EVI", "EVI2"))))


```


### QAQC: Visualize with other years
```{r}
## Convert current data format for visualization

viz_data <- index_data %>%
    select(-Spectra) %>% 
    unnest(Indices) %>% 
  
    select(-BandDefinition) %>%
    spread(Index, Value) %>%

    # Select useful columns 
    select(DateTime, Date, Site, Block, Treatment, Replicate, FileNum, NDVI, EVI, EVI2) %>%
  
    # Create additional columns 
    mutate(Year = lubridate::year(DateTime),
           DOY = lubridate::yday(DateTime)) %>%
    rename(Time = DateTime) %>%
    mutate(Block = as.numeric(str_extract(Block, "\\d"))) %>%
    mutate(Replicate = as.character(Replicate)) %>% 
    mutate(collection_year = "current") %>% 
  
    # remove non-data (ref, dark, throwaway) scans
    filter(!str_detect(Treatment, "REF|DARK|THROWAWAY"))

# Get relevant treatments and sites
viz_treatments <- viz_data$Treatment %>% unique()
viz_sites <- viz_data$Site   %>% unique()

# Read data from past years
past_data <- readRDS("indices_2014-2019.updated.rds") %>% 
  
    # Standardize Site names from 2019 version to 2020 onwards
    mutate(Site = ifelse(Site %in% c("WSG1", "WSG23"), "WSG89", Site))  %>%
    mutate(Site = ifelse(Site %in% c("DHT"), "DHT89", Site)) %>% 
    mutate(Site = ifelse(Site %in% c("MAT"), "MAT89", Site)) %>% 
    mutate(Site = ifelse(Site %in% c("LMAT"), "MAT06", Site)) %>% 
    mutate(Site = ifelse(Site %in% c("HIST"), "DHT89", Site)) %>% 
    mutate(Site = ifelse(Site %in% c("SHB2"), "SHB89", Site)) %>% 
    mutate(Site = ifelse(Site %in% c("MNAT"), "MNT97", Site)) %>% 
    mutate(Site = ifelse(Site %in% c("NANT"), "MNN97", Site)) %>% 
  
    # Label as previous years
    mutate(collection_year = "Past") %>% 
  
  # Get relevant subset of data
  filter(Treatment %in% viz_treatments) %>% 
  filter(Site %in% viz_sites) %>% 
  filter(Year >= 2017)


all_data <- past_data %>% 
  full_join(viz_data)


(plot <- ggplot(data = all_data, aes(x = DOY, 
                                     y = NDVI, 
                                     color = collection_year)) + 
    geom_point(aes(alpha = 0.01)) + 
    geom_smooth() +
    facet_grid(Site ~ Treatment)+ 
    
    #formatting
    theme_minimal()
)


```



## SAVE DATA
```{r}
# processed_spu_data <- processed_data %>%
#   
#   # remove non-data (ref, dark, throwaway) scans
#   filter(!str_detect(Treatment, "REF|DARK|THROWAWAY")) %>% 
#   
#   # adjust column names
#   select(spu_filename, DateTime, ref_filenames, processed_spectra) %>% unnest(processed_spectra) %>%
#   select(spu_filename, DateTime, ref_filenames, Wavelength, ChB, ChA, raw_reflectance, CorrectionFactor, corrected_reflectance) %>%
#   nest(Spectra = c(Wavelength, ChB, ChA, raw_reflectance, CorrectionFactor, corrected_reflectance))
# 
# ref_spu_data <- ref_data %>% unnest(Spectra) %>%
#   select(spu_filename, DateTime, Wavelength, ChB, ChA) %>%
#   mutate(Reflectance = ChB/ChA) %>% 
#   mutate(CorrectionFactor = 1/Reflectance, corrected_reflectance = NA) %>%
#   filter(Wavelength > 400, Wavelength < 1000) %>%
#   rename(raw_reflectance = Reflectance) %>%
#   nest(Spectra = c(Wavelength, ChB, ChA, raw_reflectance, CorrectionFactor, corrected_reflectance))
# 
# processed_spectra <- bind_rows(processed_spu_data, ref_spu_data)
# 
# ## Save
# processed_spu_filename <- paste0(data_path, "/", session_year, "_processed_spu_data.rds")
# 
# write_rds(df_processed, processed_spu_filename)
# 
# ## Save index data
# index_filename <- paste0(data_path, "/", params$session_date, "_index_data.rds")
# write_rds(df_indices, index_filename)

```


## CHECKLIST/SUMMARY REPORT

